{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a neural network to predict $\\delta C_9$ on an event-by-event basis (classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import log_softmax\n",
    "\n",
    "from library.plotting import setup_high_quality_mpl_params, plot_loss_curves, plot_prediction_linearity, make_plot_note\n",
    "from library.datasets import Aggregated_Signal_Binned_Dataset\n",
    "from library.util import bootstrap_over_bins\n",
    "from library.nn_training import select_device, train_and_eval\n",
    "\n",
    "\n",
    "# setup_high_quality_mpl_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_log_probabilities(x, model):\n",
    "    \"\"\"\n",
    "    Predict the log probability of each class, given a set of events.\n",
    "\n",
    "    x : A torch tensor of features of events.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        event_logits = model(x)\n",
    "        event_log_probabilities = log_softmax(event_logits, dim=1)\n",
    "        set_logits = torch.sum(event_log_probabilities, dim=0)\n",
    "        set_log_probabilities = log_softmax(set_logits, dim=0)\n",
    "    return set_log_probabilities\n",
    "\n",
    "\n",
    "def predict_log_probabilities_by_label(x, y, model):\n",
    "    \"\"\"\n",
    "    Predict the log probability of each class for each subset of same labeled events.\n",
    "    \n",
    "    x : A torch tensor of features of events (from multiple labels).\n",
    "    y : A torch tensor of event labels.\n",
    "    \"\"\"\n",
    "    labels = np.unique(y.cpu())\n",
    "    log_probabilities = []\n",
    "    for label in labels:\n",
    "        features_label = x[y==label]\n",
    "        log_probabilities_label = predict_log_probabilities(features_label, model).cpu().numpy()\n",
    "        log_probabilities.append(np.expand_dims(log_probabilities_label, axis=0))\n",
    "    log_probabilities = np.concatenate(log_probabilities, axis=0)\n",
    "    assert log_probabilities.shape == (len(labels), len(labels))\n",
    "    return log_probabilities\n",
    "\n",
    "\n",
    "def calculate_predicted_expected_value_by_label(predictions, bin_values):\n",
    "    \"\"\"\n",
    "    Calculate the predicted expected binned value for each subset of same labeled events, given \n",
    "    the predicted probability distribution for each subset.\n",
    "\n",
    "    predictions : numpy array of predicted probability distributions for each label.\n",
    "    bin_values : numpy array of the value corresponding to each bin.\n",
    "    \"\"\"\n",
    "    bin_value_shift = np.abs(np.min(bin_values)) + 1\n",
    "    shifted_bin_values = bin_values + bin_value_shift\n",
    "    log_shifted_bin_values = np.tile(np.log(shifted_bin_values), (len(shifted_bin_values), 1))\n",
    "    log_shifted_expected_values = logsumexp(predictions + log_shifted_bin_values, axis=1)\n",
    "    shifted_expected_values = np.exp(log_shifted_expected_values)\n",
    "    expected_values = shifted_expected_values - bin_value_shift\n",
    "    return expected_values\n",
    "\n",
    "\n",
    "def plot_log_probabilities_over_labels(fig, ax, predictions, bin_values, cmap=plt.cm.viridis):\n",
    "    \"\"\"\n",
    "    Plot the predicted log probability of each class for each subset of same labeled events.\n",
    "\n",
    "    predictions : A numpy array of set probabilities (rows correspond to labels, columns correspond to class predictions).\n",
    "    bin_values : A numpy array of the value each bin represents. \n",
    "    \"\"\"\n",
    "\n",
    "    color_bounds = np.append(bin_values, bin_values[-1] + (bin_values[-1] - bin_values[-2]))\n",
    "    color_norm = mpl.colors.BoundaryNorm(color_bounds, cmap.N)\n",
    "\n",
    "    for value, curve in zip(bin_values, predictions):\n",
    "        ax.plot(bin_values, curve, color=cmap(color_norm(value)))\n",
    "\n",
    "    fig.colorbar(mpl.cm.ScalarMappable(norm=color_norm, cmap=cmap), ax=ax, label=r\"Actual $\\delta C_9$\")\n",
    "    ax.set_xlabel(r\"$\\delta C_9$\")\n",
    "    ax.set_ylabel(r\"$\\log p(\\delta C_9 | x_1, ..., x_N)$\")\n",
    "\n",
    "\n",
    "def plot_expected_value_over_labels(ax, expected_values, bin_values):\n",
    "    \"\"\"\n",
    "    Plot the predicted expected value for each label.\n",
    "    \"\"\"\n",
    "    ax.scatter(bin_values, expected_values, label=\"Prediction\", color=\"firebrick\", s=16, zorder=5)\n",
    "    ax.plot(\n",
    "        bin_values, bin_values,\n",
    "        label=\"Ref. Line (Slope = 1)\",\n",
    "        color=\"grey\",\n",
    "        linewidth=0.5,\n",
    "        zorder=0\n",
    "    )\n",
    "    ax.set_xlabel(r\"Actual $\\delta C_9$\")\n",
    "    ax.set_ylabel(r\"Predicted $\\delta C_9$\")\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event_By_Event_NN(nn.Module):\n",
    "    def __init__(self, nickname):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nickname = nickname\n",
    "        self.model_dir = Path(\"../../state/new_physics/models\")\n",
    "        self.loss_table = self.make_empty_loss_table()\n",
    "\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 44),\n",
    "         )\n",
    "        \n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        event_logits = self.base(x)\n",
    "        return event_logits\n",
    "        \n",
    "    def make_final_save_path(self):\n",
    "        final_save_path = self.model_dir.joinpath(f\"{self.nickname}.pt\")\n",
    "        return final_save_path \n",
    "    \n",
    "    def save_final(self):\n",
    "        final_save_path = self.make_final_save_path()\n",
    "        torch.save(self.state_dict(), final_save_path)\n",
    "\n",
    "    def load_final(self):\n",
    "        file_path = self.make_final_save_path()\n",
    "        self.load_state_dict(torch.load(file_path, weights_only=True))\n",
    "    \n",
    "    def make_checkpoint_save_path(self, epoch_number):\n",
    "        checkpoint_save_name = self.nickname + f\"_epoch_{epoch_number}\"\n",
    "        checkpoint_save_path = self.model_dir.joinpath(f\"{checkpoint_save_name}.pt\")\n",
    "        return checkpoint_save_path\n",
    "        \n",
    "    def save_checkpoint(self, epoch_number):\n",
    "        checkpoint_save_path = self.make_checkpoint_save_path(epoch_number)\n",
    "        torch.save(self.state_dict(), checkpoint_save_path)\n",
    "\n",
    "    def load_checkpoint(self, epoch_number):\n",
    "        file_path = self.make_checkpoint_save_path(epoch_number)\n",
    "        self.load_state_dict(torch.load(file_path, weights_only=True))\n",
    "\n",
    "    def make_loss_table_file_path(self):\n",
    "        file_name = f\"{self.nickname}_loss.pkl\"\n",
    "        file_path = self.model_dir.joinpath(file_name)\n",
    "        return file_path\n",
    "    \n",
    "    def save_loss_table(self):\n",
    "        file_path = self.make_loss_table_file_path()\n",
    "        with open(file_path, \"wb\") as handle:\n",
    "            pickle.dump(self.loss_table, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def load_loss_table(self):\n",
    "        file_path = self.make_loss_table_file_path()\n",
    "        with open(file_path, \"rb\") as handle:\n",
    "            loss_table = pickle.load(handle)\n",
    "        return loss_table\n",
    "    \n",
    "    def append_to_loss_table(self, epoch, train_loss, eval_loss):\n",
    "        self.loss_table[\"epoch\"].append(epoch)\n",
    "        self.loss_table[\"train_loss\"].append(train_loss)\n",
    "        self.loss_table[\"eval_loss\"].append(eval_loss)\n",
    "        assert len(self.loss_table[\"epoch\"]) == len(self.loss_table[\"train_loss\"]) == len(self.loss_table[\"eval_loss\"])\n",
    "\n",
    "    def make_empty_loss_table(self):\n",
    "        \"\"\"Create an empty loss table.\"\"\"\n",
    "        empty_loss_table = {\"epoch\":[], \"train_loss\":[], \"eval_loss\":[]}\n",
    "        return empty_loss_table\n",
    "    \n",
    "    def clear_loss_table(self):\n",
    "        self.loss_table = self.make_empty_loss_table()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load / Generate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate = False\n",
    "\n",
    "level = \"gen\"\n",
    "save_dir = \"../../state/new_physics/data/processed\"\n",
    "raw_signal_dir = \"../../state/new_physics/data/raw/signal\"\n",
    "\n",
    "std_scale = True\n",
    "q_squared_veto = True\n",
    "\n",
    "datasets = {\n",
    "    \"train\": Aggregated_Signal_Binned_Dataset(level=level, split=\"train\", save_dir=save_dir),\n",
    "    \"eval\": Aggregated_Signal_Binned_Dataset(level=level, split=\"eval\", save_dir=save_dir),\n",
    "}\n",
    "\n",
    "if regenerate:\n",
    "    datasets[\"train\"].generate(\n",
    "        raw_trials=range(1,20), \n",
    "        raw_signal_dir=raw_signal_dir, \n",
    "        std_scale=std_scale, \n",
    "        q_squared_veto=q_squared_veto\n",
    "    )\n",
    "    datasets[\"eval\"].generate(\n",
    "        raw_trials=range(20,30), \n",
    "        raw_signal_dir=raw_signal_dir, \n",
    "        std_scale=std_scale, \n",
    "        q_squared_veto=q_squared_veto\n",
    "    )\n",
    "\n",
    "datasets[\"train\"].load(device)\n",
    "datasets[\"eval\"].load(device)\n",
    "\n",
    "np.testing.assert_equal(datasets[\"train\"].bin_values, datasets[\"eval\"].bin_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train / Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = False\n",
    "\n",
    "model = Event_By_Event_NN(\"ebe_with_checkpoints\")\n",
    "\n",
    "if retrain:\n",
    "    learning_rate = 3e-3\n",
    "    epochs = 100\n",
    "    train_batch_size = 10_000\n",
    "    eval_batch_size = 10_000\n",
    "    loss_fn = CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    loss_table = train_and_eval(\n",
    "        model, \n",
    "        datasets[\"train\"], datasets[\"eval\"], \n",
    "        loss_fn, optimizer, \n",
    "        epochs, \n",
    "        train_batch_size, eval_batch_size, \n",
    "        device, \n",
    "        move_data=True,\n",
    "        scheduler= ReduceLROnPlateau(optimizer, factor=0.95, patience=0),\n",
    "        checkpoint_epochs=5,\n",
    "    )\n",
    "    _, ax = plt.subplots()\n",
    "    plot_epoch_start = 0\n",
    "    plot_loss_curves(loss_table[\"epoch\"][plot_epoch_start:], loss_table[\"train_loss\"][plot_epoch_start:], loss_table[\"eval_loss\"][plot_epoch_start:], ax)\n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.show()\n",
    "else:\n",
    "    # model.load_final()\n",
    "    model.load_checkpoint(epoch_number=10)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_table = model.load_loss_table()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plot_epoch_start = 0\n",
    "plot_loss_curves(loss_table[\"epoch\"][plot_epoch_start:], loss_table[\"train_loss\"][plot_epoch_start:], loss_table[\"eval_loss\"][plot_epoch_start:], ax)\n",
    "# ax.set_yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(loss_table[\"eval_loss\"][50:])\n",
    "# ax.plot(loss_table[\"train_loss\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(0, 100, 5):\n",
    "\n",
    "    model.load_checkpoint(epoch_number=ep)\n",
    "    model.to(device)\n",
    "\n",
    "    fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "    log_probs = predict_log_probabilities_by_label(datasets[\"eval\"].features, datasets[\"eval\"].labels, model)\n",
    "\n",
    "    expected_values = calculate_predicted_expected_value_by_label(log_probs, datasets[\"eval\"].bin_values)\n",
    "    plot_expected_value_over_labels(ax, expected_values, datasets[\"eval\"].bin_values)\n",
    "\n",
    "    # plot_log_probabilities_over_labels(fig, ax, log_probs, datasets[\"eval\"].bin_values)\n",
    "\n",
    "    make_plot_note(ax, f\"About 77k events/prediction - Epoch: {ep}\", fontsize=\"large\")\n",
    "\n",
    "    plt.savefig(f\"plots_tmp/expected_ep_{ep}.png\", bbox_inches=\"tight\")\n",
    "\n",
    "model.load_final()\n",
    "model.to(device)\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "log_probs = predict_log_probabilities_by_label(datasets[\"eval\"].features, datasets[\"eval\"].labels, model)\n",
    "\n",
    "expected_values = calculate_predicted_expected_value_by_label(log_probs, datasets[\"eval\"].bin_values)\n",
    "plot_expected_value_over_labels(ax, expected_values, datasets[\"eval\"].bin_values)\n",
    "\n",
    "# plot_log_probabilities_over_labels(fig, ax, log_probs, datasets[\"eval\"].bin_values)\n",
    "\n",
    "make_plot_note(ax, \"About 77k events/prediction - Epoch: 99\", fontsize=\"large\")\n",
    "\n",
    "plt.savefig(\"plots_tmp/expected_ep_99.png\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On evaluation data\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "log_probs = predict_log_probabilities_by_label(datasets[\"eval\"].features, datasets[\"eval\"].labels, model)\n",
    "plot_log_probabilities_over_labels(fig, ax, log_probs, datasets[\"eval\"].bin_values)\n",
    "\n",
    "make_plot_note(ax, \"About 77k events/curve\", fontsize=\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_values = calculate_predicted_expected_value_by_label(log_probs, datasets[\"eval\"].bin_values)\n",
    "plot_expected_value_over_labels(expected_values, datasets[\"eval\"].bin_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On training data\n",
    "\n",
    "fig, ax = plt.subplots(layout=\"constrained\")\n",
    "\n",
    "log_probs = predict_log_probabilities_by_label(datasets[\"train\"].features, datasets[\"train\"].labels, model)\n",
    "plot_log_probabilities_over_labels(fig, ax, log_probs, datasets[\"train\"].bin_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_values = calculate_predicted_expected_value_by_label(log_probs, datasets[\"train\"].bin_values)\n",
    "plot_expected_value_over_labels(expected_values, datasets[\"train\"].bin_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 10\n",
    "n_events_per_trial = 70_000\n",
    "\n",
    "expected_values_all_trials = []\n",
    "for _ in range(n_trials):\n",
    "\n",
    "    boot_x, boot_y = bootstrap_over_bins(\n",
    "        datasets[\"eval\"].features.cpu().numpy(), \n",
    "        datasets[\"eval\"].labels.cpu().numpy(), \n",
    "        n_events_per_trial,\n",
    "    )\n",
    "    boot_x = torch.from_numpy(boot_x).to(device)\n",
    "    boot_y = torch.from_numpy(boot_y).to(device)\n",
    "\n",
    "    log_probs = predict_log_probabilities_by_label(boot_x, boot_y, model)\n",
    "    expected_values = calculate_predicted_expected_value_by_label(log_probs, datasets[\"eval\"].bin_values)\n",
    "    expected_values_all_trials.append(np.expand_dims(expected_values, axis=0))\n",
    "\n",
    "expected_values_all_trials = np.concat(expected_values_all_trials)\n",
    "\n",
    "expected_values_all_trials_means = np.mean(expected_values_all_trials, axis=0)\n",
    "expected_values_all_trials_stds = np.std(expected_values_all_trials, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plot_prediction_linearity(\n",
    "    ax,\n",
    "    datasets[\"eval\"].bin_values,\n",
    "    expected_values_all_trials_means,\n",
    "    expected_values_all_trials_stds,\n",
    "    ref_line_buffer=0.05,\n",
    "    xlim=(-2.25, 1.35),\n",
    "    ylim=(-2.25, 1.35),\n",
    "    xlabel=r\"Actual $\\delta C_9$\", \n",
    "    ylabel=r\"Predicted $\\delta C_9$\"\n",
    ")\n",
    "\n",
    "make_plot_note(ax, f\"{n_trials} bootstrapped trials, {n_events_per_trial} events/trial\", fontsize=\"large\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maybe_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
