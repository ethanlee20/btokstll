{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B \\rightarrow K^* \\ell \\ell$  machine learning experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "from torch.nn import MSELoss, CrossEntropyLoss\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.datasets.make_and_save.aggregated_signal import Aggregated_Signal_Dataframe_Handler\n",
    "from helpers.datasets.constants import Names_of_Levels, Names_of_q_Squared_Vetos, Raw_Signal_Trial_Ranges, Numbers_of_Events_per_Set, Names_of_Splits, Names_of_Labels\n",
    "from helpers.experiment.experiment import CNN_Group, Deep_Sets_Group, Event_by_Event_Group\n",
    "from helpers.experiment.results_table import Results_Table\n",
    "from helpers.experiment.constants import Paths_to_Directories, delta_C9_value_new_physics, delta_C9_value_standard_model\n",
    "from helpers.models.hardware_util import select_device\n",
    "from helpers.experiment.experiment import evaluate_model\n",
    "from helpers.datasets.settings.settings import Binned_Sets_Dataset_Settings\n",
    "from helpers.datasets.datasets import Unbinned_Sets_Dataset, Binned_Sets_Dataset, Images_Dataset\n",
    "from helpers.datasets.make_and_save.preprocessing import apply_q_squared_veto\n",
    "\n",
    "from helpers.plot.linearity import plot_linearity\n",
    "from helpers.plot.probabilities import plot_log_probability_distribution_examples\n",
    "\n",
    "results_table = Results_Table()\n",
    "device = select_device()\n",
    "\n",
    "mpl.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "mpl.rcParams[\"figure.dpi\"] = 400\n",
    "mpl.rcParams[\"axes.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.titlesize\"] = 8\n",
    "mpl.rcParams[\"figure.labelsize\"] = 30\n",
    "mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{bm}\"\n",
    "mpl.rcParams[\"font.family\"] = \"serif\"\n",
    "mpl.rcParams[\"font.serif\"] = [\"Computer Modern\"]\n",
    "mpl.rcParams[\"font.size\"] = 8\n",
    "mpl.rcParams[\"axes.titley\"] = None\n",
    "mpl.rcParams[\"axes.titlepad\"] = 2\n",
    "mpl.rcParams[\"legend.fancybox\"] = False\n",
    "mpl.rcParams[\"legend.framealpha\"] = 0\n",
    "mpl.rcParams[\"legend.markerscale\"] = 1\n",
    "mpl.rcParams[\"legend.fontsize\"] = 7.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remake aggregated signal dataframe files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in (Names_of_Levels().generator, Names_of_Levels().detector):\n",
    "    for trial_range in Raw_Signal_Trial_Ranges().tuple_:\n",
    "        \n",
    "        Aggregated_Signal_Dataframe_Handler(\n",
    "            path_to_main_datasets_dir=Paths_to_Directories().path_to_main_datasets_dir,\n",
    "            level=level,\n",
    "            trial_range=trial_range\n",
    "        ).make_and_save(Paths_to_Directories().path_to_raw_signal_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sets_group = Deep_Sets_Group(\n",
    "    num_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_sets_per_label_sensitivity=2_000,\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=MSELoss(),\n",
    "    learning_rate=3e-4,\n",
    "    learning_rate_scheduler_reduction_factor=0.97,\n",
    "    size_of_training_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    size_of_evaluation_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    number_of_epochs=100,\n",
    "    number_of_epochs_between_checkpoints=1,\n",
    "    results_table=results_table,\n",
    "    device=device,\n",
    "    bkg_fraction=0.2,\n",
    "    bkg_charge_fraction=0.5\n",
    ")\n",
    "\n",
    "deep_sets_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "levels = (Names_of_Levels().generator, Names_of_Levels().detector)\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=deep_sets_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{deep_sets_group.get_individual(level=level, num_events_per_set=num_events_per_set).evaluation_dataset_settings.set.num_sets_per_label}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(f\"Deep sets\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"deep_sets_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\70000_eval_sens_labels.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\experiment\\results_table.py:49: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\24000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\24000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([25652, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([25652]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\6000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_resonances\\6000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\70000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\24000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\24000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([25652, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([25652]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\6000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_resonances\\6000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\70000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([6380, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([6380]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\24000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\24000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n",
      "Loaded tensor of shape: torch.Size([25652, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([25652]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\6000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_resonances\\6000_eval_sens_labels.pt\n",
      "Unloaded datasets.\n",
      "Unloaded datasets.\n"
     ]
    }
   ],
   "source": [
    "cnn_group = CNN_Group(\n",
    "    num_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_sets_per_label_sensitivity=2_000,\n",
    "    num_bins_per_dimension=10,\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=MSELoss(),\n",
    "    learning_rate=3e-4,\n",
    "    learning_rate_scheduler_reduction_factor=0.95,\n",
    "    size_of_training_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    size_of_evaluation_batch={6_000 : 373, 24_000 : 93, 70_000 : 32},\n",
    "    number_of_epochs=50,\n",
    "    number_of_epochs_between_checkpoints=1,\n",
    "    results_table=results_table,\n",
    "    device=device,\n",
    "    bkg_fraction=0.2,\n",
    "    bkg_charge_fraction=0.5\n",
    ")\n",
    "\n",
    "# cnn_group.train_subset(levels=[Names_of_Levels().detector,], nums_events_per_set=[6_000,], remake_datasets=True)\n",
    "cnn_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "levels = (Names_of_Levels().generator, Names_of_Levels().detector)\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=cnn_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{cnn_group.num_sets_per_label[num_events_per_set]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "# fig.suptitle(f\"CNN, bins/dim.: {cnn_group.num_bins_per_dimension}\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.suptitle(f\"CNN\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"cnn_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def plot_image_slices(\n",
    "    image,\n",
    "    norm, \n",
    "    cmap,\n",
    "    ax_3d,\n",
    "    num_slices=3, \n",
    "):  \n",
    "\n",
    "    def xy_plane_at(z_position):\n",
    "        x, y = numpy.indices(\n",
    "            (\n",
    "                axis_dimension_from_cartesian[\"x\"] + 1, \n",
    "                axis_dimension_from_cartesian[\"y\"] + 1\n",
    "            )\n",
    "        )\n",
    "        z = numpy.full(\n",
    "            (\n",
    "                axis_dimension_from_cartesian[\"x\"] + 1, \n",
    "                axis_dimension_from_cartesian[\"y\"] + 1\n",
    "            ), \n",
    "            z_position\n",
    "        )\n",
    "        return x, y, z\n",
    "    \n",
    "    def plot_slice(z_index):\n",
    "        x, y, z = xy_plane_at(z_index) \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            facecolors=colors[:,:,z_index], \n",
    "            shade=False\n",
    "        )\n",
    "\n",
    "    def plot_outline(z_index, offset=0.3):\n",
    "        x, y, z = xy_plane_at(z_index - offset)\n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, \n",
    "            cstride=1, \n",
    "            shade=False,\n",
    "            color=\"#f2f2f2\",\n",
    "            edgecolor=\"#f2f2f2\"\n",
    "        )\n",
    "\n",
    "    image = image.squeeze().cpu()\n",
    "    colors = cmap(norm(image))\n",
    "    \n",
    "    axis_index_from_cartesian = {\n",
    "        \"x\": 0,\n",
    "        \"y\": 1,\n",
    "        \"z\": 2\n",
    "    }\n",
    "    axis_dimension_from_cartesian = {\n",
    "        \"x\": image.shape[axis_index_from_cartesian[\"x\"]],\n",
    "        \"y\": image.shape[axis_index_from_cartesian[\"y\"]],\n",
    "        \"z\": image.shape[axis_index_from_cartesian[\"z\"]]\n",
    "    }\n",
    "    z_indices = numpy.linspace( \n",
    "        start=0, \n",
    "        stop=axis_dimension_from_cartesian[\"z\"]-1, \n",
    "        num=num_slices, \n",
    "        dtype=int  # forces integer indices\n",
    "    ) \n",
    "    for i in z_indices:\n",
    "        plot_outline(i)\n",
    "        plot_slice(i)\n",
    "\n",
    "\n",
    "    ax_labels = {\n",
    "        \"x\": r\"$\\cos\\theta_\\mu$\",\n",
    "        \"y\": r\"$\\cos\\theta_K$\",\n",
    "        \"z\": r\"$\\chi$\"\n",
    "    }\n",
    "    # ax_3d.set_axis_off()\n",
    "    ax_3d.tick_params(\n",
    "        axis=\"both\",\n",
    "        which=\"both\",\n",
    "        bottom=False,\n",
    "        top=True,\n",
    "        labelbottom=False,\n",
    "        labeltop=False,\n",
    "        labelleft=False,\n",
    "        labelright=False\n",
    "    )\n",
    "    ax_3d.set_xlabel(ax_labels[\"x\"], labelpad=-16)\n",
    "    ax_3d.set_ylabel(ax_labels[\"y\"], labelpad=-16)\n",
    "    ax_3d.set_zlabel(ax_labels[\"z\"], labelpad=-16)\n",
    "    # ax_3d.set_box_aspect(None, zoom=0.85)\n",
    "    \n",
    "\n",
    "for delta_c9 in (delta_C9_value_standard_model, delta_C9_value_new_physics):\n",
    "\n",
    "    fig, axs = plt.subplots(2, 3, subplot_kw={\"projection\":\"3d\"}, layout=\"compressed\")\n",
    "    norm = mpl.colors.Normalize(vmin=-1, vmax=1)\n",
    "    cmap = plt.cm.magma\n",
    "    cbar = fig.colorbar(\n",
    "        mpl.cm.ScalarMappable(norm=norm, cmap=cmap), \n",
    "        ax=axs, \n",
    "        location=\"right\", \n",
    "        shrink=0.6,     \n",
    "    )\n",
    "    cbar.set_label(r\"Normalized ${q^2}$ (Avg.)\", size=11)\n",
    "    cbar.set_ticks([])\n",
    "        \n",
    "    levels = (Names_of_Levels().generator, Names_of_Levels().detector)\n",
    "    names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "    for (level, num_events_per_set), ax in zip(product(levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "\n",
    "        dataset = Images_Dataset(settings=cnn_group.get_individual(level=level, num_events_per_set=num_events_per_set).evaluation_dataset_settings)\n",
    "        dataset.load()\n",
    "        plot_image_slices(\n",
    "            image=dataset.features[dataset.labels==delta_c9][0],\n",
    "            norm=norm,\n",
    "            cmap=cmap,\n",
    "            ax_3d=ax\n",
    "        )\n",
    "        ax.set_title(\n",
    "            (\n",
    "                f\"Level: {names_of_levels[level]}\"\n",
    "                f\"\\nEvents: {num_events_per_set}\"\n",
    "            ),\n",
    "            loc=\"left\",\n",
    "            y=0.97\n",
    "        )\n",
    "\n",
    "    delta_c9_description = (\n",
    "        r\"SM ($\\delta C_9 = \" + f\"{delta_C9_value_standard_model}\" + r\"$)\" if delta_c9 == delta_C9_value_standard_model\n",
    "        else r\"NP ($\\delta C_9 = \" + f\"{delta_C9_value_new_physics}\" + r\"$)\" if delta_c9 == delta_C9_value_new_physics\n",
    "        else None\n",
    "    )\n",
    "    if delta_c9_description is None: raise ValueError\n",
    "\n",
    "    fig.suptitle(\n",
    "        (\n",
    "            f\"Images, \"\n",
    "            + f\"bins/dim.: {cnn_group.num_bins_per_dimension}, \"\n",
    "            + delta_c9_description\n",
    "            + \"\\n\"\n",
    "        ), \n",
    "        x=0.02, \n",
    "        horizontalalignment=\"left\"\n",
    "    )\n",
    "\n",
    "    save_name = (\n",
    "        \"image_grid_SM.png\" if delta_c9 == delta_C9_value_standard_model\n",
    "        else \"image_grid_NP.png\" if delta_c9 == delta_C9_value_new_physics\n",
    "        else None\n",
    "    )\n",
    "    if save_name is None: raise ValueError\n",
    "\n",
    "    plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(save_name), bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event-by-event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_by_event_group = Event_by_Event_Group(\n",
    "    num_evaluation_sets_per_label={6_000 : 583, 24_000 : 145, 70_000 : 50},\n",
    "    num_evaluation_sets_per_label_sensitivity=2_000,\n",
    "    q_squared_veto=Names_of_q_Squared_Vetos().resonances,\n",
    "    std_scale=True,\n",
    "    shuffle=True,\n",
    "    uniform_label_counts=True,\n",
    "    loss_fn=CrossEntropyLoss(),\n",
    "    learning_rate=3e-3,\n",
    "    learning_rate_scheduler_reduction_factor=0.95,\n",
    "    size_of_training_batch=10_000,\n",
    "    size_of_evaluation_batch=10_000,\n",
    "    number_of_epochs=300,\n",
    "    number_of_epochs_between_checkpoints=2,\n",
    "    results_table=results_table,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# event_by_event_group.train_subset(levels=[Names_of_Levels().detector], remake_datasets=True)\n",
    "event_by_event_group.evaluate_all(remake_datasets=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "names_of_levels = {Names_of_Levels().generator : \"Generator\", Names_of_Levels().detector : \"Detector\"}\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(event_by_event_group.possible_levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    plot_linearity(\n",
    "        linearity_test_results=event_by_event_group.results[level][num_events_per_set].linearity_results, \n",
    "        ax=ax,\n",
    "    )\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Level: {names_of_levels[level]}\"\n",
    "        f\"\\nEvents/set: {num_events_per_set}\"\n",
    "        \"\\n\" + r\"Sets/$\\delta C_9$: \" + f\"{event_by_event_group.num_evaluation_sets_per_label[num_events_per_set]}\", \n",
    "        loc=\"left\"\n",
    "    )\n",
    "\n",
    "axs.flat[0].legend()\n",
    "fig.suptitle(\"Event-by-event\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"Actual $\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"Predicted $\\delta C_9$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"ebe_grid_lin.png\"), bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, sharex=True, sharey=True, layout=\"compressed\")\n",
    "\n",
    "for (level, num_events_per_set), ax in zip(product(event_by_event_group.possible_levels, Numbers_of_Events_per_Set().tuple_), axs.flat):\n",
    "    \n",
    "    dataset = Binned_Sets_Dataset(settings=event_by_event_group.get_individual(level)._get_evaluation_set_dataset_settings(num_events_per_set))\n",
    "    dataset.load()\n",
    "\n",
    "    plot_log_probability_distribution_examples(\n",
    "        log_probabilities=event_by_event_group.results[level][num_events_per_set].log_probabilities, \n",
    "        binned_labels=dataset.labels,\n",
    "        bin_map=dataset.bin_map,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"Level: {names_of_levels[level]}\\nEvents: {num_events_per_set}\", loc=\"left\")\n",
    "\n",
    "axs.flat[0].legend(loc=\"lower right\", markerscale=2)\n",
    "fig.suptitle(\"Event-by-event\\n\", x=0.02, horizontalalignment=\"left\")\n",
    "fig.supxlabel(r\"$\\delta C_9$\", fontsize=11, x=0.56, y=-0.06)\n",
    "fig.supylabel(r\"$\\log\\;p(\\delta C_9 | x_1, ..., x_N)$\", fontsize=11, y=0.45)\n",
    "\n",
    "plt.savefig(Paths_to_Directories().path_to_plots_dir.joinpath(\"ebe_grid_proba.png\"), bbox_inches=\"tight\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charge_train = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_train.pkl\")\n",
    "mix_train = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_train.pkl\")\n",
    "all_train = pandas.concat([charge_train, mix_train])\n",
    "\n",
    "charge_eval = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_eval.pkl\")\n",
    "mix_eval = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_eval.pkl\")\n",
    "all_eval = pandas.concat([charge_eval, mix_eval])\n",
    "\n",
    "charge_eval = apply_q_squared_veto(charge_eval, Names_of_q_Squared_Vetos().resonances)\n",
    "charge_train = apply_q_squared_veto(charge_train, Names_of_q_Squared_Vetos().resonances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
