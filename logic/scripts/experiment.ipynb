{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07eca79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from helpers.model.util import select_device\n",
    "from helpers.experiment.experiment import Experiment\n",
    "from helpers.experiment.configs import (\n",
    "    Config_Experiment_Images,\n",
    "    Config_Experiment_Deep_Sets,\n",
    "    Config_Experiment_Event_by_Event\n",
    ")\n",
    "from helpers.data.dset.config import Config_Dataset\n",
    "from helpers.data.dset.constants import (\n",
    "    Names_Datasets,\n",
    "    Names_Levels,\n",
    "    Names_q_Squared_Vetos,\n",
    "    Names_Splits,\n",
    "    Names_Variables,\n",
    "    Nums_Events_Per_Set\n",
    ")\n",
    "from helpers.model.config import Config_Model\n",
    "from helpers.model.constants import Names_Models\n",
    "from helpers.plot.util import setup_high_quality_mpl_params\n",
    "\n",
    "\n",
    "setup_high_quality_mpl_params()\n",
    "\n",
    "path_dir_plots = \"../../state/new_physics/plots\"\n",
    "\n",
    "\n",
    "device = select_device()\n",
    "\n",
    "\n",
    "experiment = Experiment(\n",
    "    path_dir_plots=path_dir_plots,\n",
    "    device=device,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f94f9f",
   "metadata": {},
   "source": [
    "Images Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69862d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_experiment_images = Config_Experiment_Images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f63f8a1",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b1b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in (Names_Levels().detector_and_background,):\n",
    "\n",
    "    for num_events_per_set in Nums_Events_Per_Set().tuple_:\n",
    "\n",
    "        experiment.train(\n",
    "            config_model=config_experiment_images.get_config_model(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set\n",
    "            ),\n",
    "            config_dset_eval=config_experiment_images.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval\"\n",
    "            ),\n",
    "            generate_dsets=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd3b5b5",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e895a09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_gen_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: images\n",
      "Loaded tensor of shape: torch.Size([2200, 1, 10, 10, 10]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\images_det_bkg_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    }
   ],
   "source": [
    "for level in Names_Levels().tuple_:\n",
    "\n",
    "    for num_events_per_set in Nums_Events_Per_Set().tuple_:\n",
    "\n",
    "        experiment.evaluate(\n",
    "            config_model=config_experiment_images.get_config_model(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set\n",
    "            ), \n",
    "            config_dset_eval=config_experiment_images.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval\"\n",
    "            ),\n",
    "            config_dset_eval_sens=config_experiment_images.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval_sens\"\n",
    "            ),\n",
    "            generate_dsets=False, \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84419439",
   "metadata": {},
   "source": [
    "Deep Sets Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "596d236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_experiment_deep_sets = Config_Experiment_Deep_Sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6605b",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b798a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "for level in (Names_Levels().detector_and_background,):\n",
    "\n",
    "    for num_events_per_set in Nums_Events_Per_Set().tuple_:\n",
    "\n",
    "        experiment.train(\n",
    "            config_model=config_experiment_deep_sets.get_config_model(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set\n",
    "            ),\n",
    "            config_dset_eval=config_experiment_deep_sets.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval\"\n",
    "            ),\n",
    "            generate_dsets=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66252005",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbc3e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_gen_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2000, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded dataset: sets_unbinned\n",
      "Loaded tensor of shape: torch.Size([2200, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_unbinned_det_bkg_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded dataset: sets_unbinned\n"
     ]
    }
   ],
   "source": [
    "for level in Names_Levels().tuple_:\n",
    "\n",
    "    for num_events_per_set in Nums_Events_Per_Set().tuple_:\n",
    "\n",
    "        experiment.evaluate(\n",
    "            config_model=config_experiment_deep_sets.get_config_model(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set\n",
    "            ), \n",
    "            config_dset_eval=config_experiment_deep_sets.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval\"\n",
    "            ),\n",
    "            config_dset_eval_sens=config_experiment_deep_sets.get_config_dset(\n",
    "                level=level, \n",
    "                num_events_per_set=num_events_per_set, \n",
    "                kind=\"eval_sens\"\n",
    "            ),\n",
    "            generate_dsets=False, \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ba487b",
   "metadata": {},
   "source": [
    "Event by event Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2281addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_experiment_ebe = Config_Experiment_Event_by_Event()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02012e46",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b9e0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened ..\\..\\state\\new_physics\\data\\processed\\agg_sig_1_to_20_det.pkl\n",
      "Loaded aggregated raw signal data file: ..\\..\\state\\new_physics\\data\\processed\\agg_sig_1_to_20_det.pkl\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      144\n",
      "costheta_K       670\n",
      "chi              670\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Loaded raw bkg file: ..\\..\\state\\new_physics\\data\\raw\\bkg\\mu_sideb_generic_charge_train_scaled.pkl\n",
      "Loaded raw bkg file: ..\\..\\state\\new_physics\\data\\raw\\bkg\\mu_sideb_generic_mix_train_scaled.pkl\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Generated tensor of shape: torch.Size([9330430, 4]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_features.pt\n",
      "Generated tensor of shape: torch.Size([9330430, 44]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_labels.pt\n",
      "Generated tensor of shape: torch.Size([44]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_bin_map.pt\n",
      "Generated dataset: events_binned\n",
      "Opened ..\\..\\state\\new_physics\\data\\processed\\agg_sig_21_to_40_det.pkl\n",
      "Loaded aggregated raw signal data file: ..\\..\\state\\new_physics\\data\\processed\\agg_sig_21_to_40_det.pkl\n",
      "Number of NA values: \n",
      " q_squared          0\n",
      "costheta_mu      139\n",
      "costheta_K       619\n",
      "chi              619\n",
      "dc9_bin_index      0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Loaded raw bkg file: ..\\..\\state\\new_physics\\data\\raw\\bkg\\mu_sideb_generic_charge_eval_scaled.pkl\n",
      "Loaded raw bkg file: ..\\..\\state\\new_physics\\data\\raw\\bkg\\mu_sideb_generic_mix_eval_scaled.pkl\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Number of NA values: \n",
      " q_squared      0\n",
      "costheta_mu    0\n",
      "costheta_K     0\n",
      "chi            0\n",
      "dtype: int64\n",
      "Removed NA rows.\n",
      "Shuffled dataframe.\n",
      "Applied cleaning.\n",
      "Generated tensor of shape: torch.Size([9290822, 4]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_features.pt\n",
      "Generated tensor of shape: torch.Size([9290822, 44]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_labels.pt\n",
      "Generated tensor of shape: torch.Size([44]).\n",
      "Saved as: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_bin_map.pt\n",
      "Generated dataset: events_binned\n",
      "Loaded tensor of shape: torch.Size([9330430, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_features.pt\n",
      "Loaded tensor of shape: torch.Size([9330430, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\train_bin_map.pt\n",
      "Loaded dataset: events_binned\n",
      "Loaded tensor of shape: torch.Size([9290822, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([9290822, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\events_binned_det_bkg_q2v_loose\\eval_bin_map.pt\n",
      "Loaded dataset: events_binned\n",
      "\n",
      "Epoch 0 complete:\n",
      "    Train loss: 3.7831519687878847\n",
      "    Eval loss: 3.7826773887634357\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 0\n",
      "\n",
      "Epoch 1 complete:\n",
      "    Train loss: 3.7826121593130213\n",
      "    Eval loss: 3.782620574746567\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 2 complete:\n",
      "    Train loss: 3.782552150821221\n",
      "    Eval loss: 3.7825963057584295\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 3 complete:\n",
      "    Train loss: 3.7825244027804366\n",
      "    Eval loss: 3.78257822500606\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 4 complete:\n",
      "    Train loss: 3.7825044207118586\n",
      "    Eval loss: 3.7825643789142913\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 5 complete:\n",
      "    Train loss: 3.7824891209229854\n",
      "    Eval loss: 3.7825509981834085\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 5\n",
      "\n",
      "Epoch 6 complete:\n",
      "    Train loss: 3.782477861017293\n",
      "    Eval loss: 3.7825423996248806\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 7 complete:\n",
      "    Train loss: 3.782469825692996\n",
      "    Eval loss: 3.7825403794486623\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 8 complete:\n",
      "    Train loss: 3.7824642866449234\n",
      "    Eval loss: 3.7825347905580857\n",
      "\n",
      "Learning rate: [0.003]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 9 complete:\n",
      "    Train loss: 3.7824581878521206\n",
      "    Eval loss: 3.7825368592975983\n",
      "\n",
      "Learning rate: [0.00285]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 10 complete:\n",
      "    Train loss: 3.7824479123571884\n",
      "    Eval loss: 3.78252552146083\n",
      "\n",
      "Learning rate: [0.00285]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 10\n",
      "\n",
      "Epoch 11 complete:\n",
      "    Train loss: 3.7824429368284753\n",
      "    Eval loss: 3.7825169571315422\n",
      "\n",
      "Learning rate: [0.00285]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 12 complete:\n",
      "    Train loss: 3.7824385925074937\n",
      "    Eval loss: 3.7825205157541704\n",
      "\n",
      "Learning rate: [0.0027075]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 13 complete:\n",
      "    Train loss: 3.782429363122163\n",
      "    Eval loss: 3.7825170589567283\n",
      "\n",
      "Learning rate: [0.0025721249999999998]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 14 complete:\n",
      "    Train loss: 3.782422458634864\n",
      "    Eval loss: 3.7825067327334314\n",
      "\n",
      "Learning rate: [0.0025721249999999998]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 15 complete:\n",
      "    Train loss: 3.7824197089806972\n",
      "    Eval loss: 3.7825088070213875\n",
      "\n",
      "Learning rate: [0.0024435187499999996]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 15\n",
      "\n",
      "Epoch 16 complete:\n",
      "    Train loss: 3.782410789580696\n",
      "    Eval loss: 3.7825128248035806\n",
      "\n",
      "Learning rate: [0.0023213428124999997]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 17 complete:\n",
      "    Train loss: 3.7824024404993843\n",
      "    Eval loss: 3.782508025565453\n",
      "\n",
      "Learning rate: [0.0022052756718749997]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 18 complete:\n",
      "    Train loss: 3.782393585715084\n",
      "    Eval loss: 3.782504205711432\n",
      "\n",
      "Learning rate: [0.0022052756718749997]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 19 complete:\n",
      "    Train loss: 3.782392748295304\n",
      "    Eval loss: 3.7825011134607345\n",
      "\n",
      "Learning rate: [0.0022052756718749997]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 20 complete:\n",
      "    Train loss: 3.782389526947145\n",
      "    Eval loss: 3.782494946171155\n",
      "\n",
      "Learning rate: [0.0022052756718749997]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 20\n",
      "\n",
      "Epoch 21 complete:\n",
      "    Train loss: 3.7823850935211576\n",
      "    Eval loss: 3.7825004524864547\n",
      "\n",
      "Learning rate: [0.0020950118882812497]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 22 complete:\n",
      "    Train loss: 3.782378237492316\n",
      "    Eval loss: 3.7824928458584286\n",
      "\n",
      "Learning rate: [0.0020950118882812497]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 23 complete:\n",
      "    Train loss: 3.7823768652767535\n",
      "    Eval loss: 3.782493104019798\n",
      "\n",
      "Learning rate: [0.001990261293867187]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 24 complete:\n",
      "    Train loss: 3.7823713774248184\n",
      "    Eval loss: 3.7824885894987226\n",
      "\n",
      "Learning rate: [0.001990261293867187]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 25 complete:\n",
      "    Train loss: 3.7823685943492307\n",
      "    Eval loss: 3.782483080302138\n",
      "\n",
      "Learning rate: [0.001990261293867187]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 25\n",
      "\n",
      "Epoch 26 complete:\n",
      "    Train loss: 3.7823687788175\n",
      "    Eval loss: 3.78248589414333\n",
      "\n",
      "Learning rate: [0.0018907482291738277]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 27 complete:\n",
      "    Train loss: 3.78236268891516\n",
      "    Eval loss: 3.7824803572936254\n",
      "\n",
      "Learning rate: [0.0018907482291738277]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 28 complete:\n",
      "    Train loss: 3.782361681779361\n",
      "    Eval loss: 3.782481673015581\n",
      "\n",
      "Learning rate: [0.0017962108177151362]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 29 complete:\n",
      "    Train loss: 3.7823567149354282\n",
      "    Eval loss: 3.7824826628068315\n",
      "\n",
      "Learning rate: [0.0017064002768293794]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 30 complete:\n",
      "    Train loss: 3.7823516242529487\n",
      "    Eval loss: 3.782470115239866\n",
      "\n",
      "Learning rate: [0.0017064002768293794]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 30\n",
      "\n",
      "Epoch 31 complete:\n",
      "    Train loss: 3.7823504015629985\n",
      "    Eval loss: 3.7824755663825016\n",
      "\n",
      "Learning rate: [0.0016210802629879103]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 32 complete:\n",
      "    Train loss: 3.7823445995572\n",
      "    Eval loss: 3.782471369830582\n",
      "\n",
      "Learning rate: [0.0015400262498385148]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 33 complete:\n",
      "    Train loss: 3.78234052838048\n",
      "    Eval loss: 3.7824685472356703\n",
      "\n",
      "Learning rate: [0.0015400262498385148]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 34 complete:\n",
      "    Train loss: 3.7823395193012246\n",
      "    Eval loss: 3.7824663968817536\n",
      "\n",
      "Learning rate: [0.0015400262498385148]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 35 complete:\n",
      "    Train loss: 3.782338745293842\n",
      "    Eval loss: 3.7824629305265627\n",
      "\n",
      "Learning rate: [0.0015400262498385148]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 35\n",
      "\n",
      "Epoch 36 complete:\n",
      "    Train loss: 3.7823375746156476\n",
      "    Eval loss: 3.782465154012315\n",
      "\n",
      "Learning rate: [0.001463024937346589]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 37 complete:\n",
      "    Train loss: 3.7823329089512177\n",
      "    Eval loss: 3.7824634156192714\n",
      "\n",
      "Learning rate: [0.0013898736904792595]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 38 complete:\n",
      "    Train loss: 3.782328428205728\n",
      "    Eval loss: 3.782457742845092\n",
      "\n",
      "Learning rate: [0.0013898736904792595]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 39 complete:\n",
      "    Train loss: 3.7823282155425026\n",
      "    Eval loss: 3.7824577501212717\n",
      "\n",
      "Learning rate: [0.0013203800059552965]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 40 complete:\n",
      "    Train loss: 3.78232352377056\n",
      "    Eval loss: 3.7824577638086097\n",
      "\n",
      "Learning rate: [0.0012543610056575316]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 40\n",
      "\n",
      "Epoch 41 complete:\n",
      "    Train loss: 3.782319548545308\n",
      "    Eval loss: 3.7824579744696565\n",
      "\n",
      "Learning rate: [0.001191642955374655]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 42 complete:\n",
      "    Train loss: 3.782316725665571\n",
      "    Eval loss: 3.782454646732611\n",
      "\n",
      "Learning rate: [0.001191642955374655]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 43 complete:\n",
      "    Train loss: 3.7823147668156274\n",
      "    Eval loss: 3.782455636646833\n",
      "\n",
      "Learning rate: [0.001132060807605922]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 44 complete:\n",
      "    Train loss: 3.782312481940387\n",
      "    Eval loss: 3.7824550130700056\n",
      "\n",
      "Learning rate: [0.0010754577672256258]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 45 complete:\n",
      "    Train loss: 3.7823082648683375\n",
      "    Eval loss: 3.782453045085868\n",
      "\n",
      "Learning rate: [0.0010754577672256258]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 45\n",
      "\n",
      "Epoch 46 complete:\n",
      "    Train loss: 3.7823074758666384\n",
      "    Eval loss: 3.782453011281064\n",
      "\n",
      "Learning rate: [0.0010754577672256258]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 47 complete:\n",
      "    Train loss: 3.7823072321970757\n",
      "    Eval loss: 3.7824512749102954\n",
      "\n",
      "Learning rate: [0.0010754577672256258]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 48 complete:\n",
      "    Train loss: 3.7823066262498592\n",
      "    Eval loss: 3.7824530371217784\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 49 complete:\n",
      "    Train loss: 3.7823037956247476\n",
      "    Eval loss: 3.7824491874946524\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 50 complete:\n",
      "    Train loss: 3.7823031159709783\n",
      "    Eval loss: 3.7824491159903073\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 50\n",
      "\n",
      "Epoch 51 complete:\n",
      "    Train loss: 3.782302630578819\n",
      "    Eval loss: 3.782447102060613\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 52 complete:\n",
      "    Train loss: 3.7823019700545966\n",
      "    Eval loss: 3.7824466791791123\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 53 complete:\n",
      "    Train loss: 3.782301909057182\n",
      "    Eval loss: 3.7824456693463953\n",
      "\n",
      "Learning rate: [0.0010216848788643445]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 54 complete:\n",
      "    Train loss: 3.7823015532517346\n",
      "    Eval loss: 3.7824460927473806\n",
      "\n",
      "Learning rate: [0.0009706006349211272]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 55 complete:\n",
      "    Train loss: 3.782298489575893\n",
      "    Eval loss: 3.7824448756602536\n",
      "\n",
      "Learning rate: [0.0009706006349211272]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 55\n",
      "\n",
      "Epoch 56 complete:\n",
      "    Train loss: 3.7822979491694446\n",
      "    Eval loss: 3.7824503929463\n",
      "\n",
      "Learning rate: [0.0009220706031750709]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 57 complete:\n",
      "    Train loss: 3.782295384408298\n",
      "    Eval loss: 3.782448747369409\n",
      "\n",
      "Learning rate: [0.0008759670730163172]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 58 complete:\n",
      "    Train loss: 3.7822926985410725\n",
      "    Eval loss: 3.7824458092511395\n",
      "\n",
      "Learning rate: [0.0008321687193655013]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 59 complete:\n",
      "    Train loss: 3.782290501258507\n",
      "    Eval loss: 3.7824455708682225\n",
      "\n",
      "Learning rate: [0.0007905602833972262]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 60 complete:\n",
      "    Train loss: 3.782288016372756\n",
      "    Eval loss: 3.7824473001912686\n",
      "\n",
      "Learning rate: [0.0007510322692273649]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 60\n",
      "\n",
      "Epoch 61 complete:\n",
      "    Train loss: 3.782285236165696\n",
      "    Eval loss: 3.782445303814377\n",
      "\n",
      "Learning rate: [0.0007134806557659966]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 62 complete:\n",
      "    Train loss: 3.7822823313667007\n",
      "    Eval loss: 3.7824461540149397\n",
      "\n",
      "Learning rate: [0.0006778066229776968]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 63 complete:\n",
      "    Train loss: 3.782280317316781\n",
      "    Eval loss: 3.7824456669090623\n",
      "\n",
      "Learning rate: [0.0006439162918288119]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 64 complete:\n",
      "    Train loss: 3.7822781073044007\n",
      "    Eval loss: 3.782444732434909\n",
      "\n",
      "Learning rate: [0.0006439162918288119]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 65 complete:\n",
      "    Train loss: 3.7822776703468857\n",
      "    Eval loss: 3.782445040670485\n",
      "\n",
      "Learning rate: [0.0006117204772373713]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 65\n",
      "\n",
      "Epoch 66 complete:\n",
      "    Train loss: 3.7822757796693813\n",
      "    Eval loss: 3.7824435558048384\n",
      "\n",
      "Learning rate: [0.0006117204772373713]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 67 complete:\n",
      "    Train loss: 3.782275274583177\n",
      "    Eval loss: 3.782443404241601\n",
      "\n",
      "Learning rate: [0.0006117204772373713]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 68 complete:\n",
      "    Train loss: 3.7822752041409253\n",
      "    Eval loss: 3.782444028376109\n",
      "\n",
      "Learning rate: [0.0005811344533755027]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 69 complete:\n",
      "    Train loss: 3.782273087760656\n",
      "    Eval loss: 3.7824425927354683\n",
      "\n",
      "Learning rate: [0.0005811344533755027]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 70 complete:\n",
      "    Train loss: 3.782272797285774\n",
      "    Eval loss: 3.7824428197183084\n",
      "\n",
      "Learning rate: [0.0005520777307067275]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 70\n",
      "\n",
      "Epoch 71 complete:\n",
      "    Train loss: 3.782271207853762\n",
      "    Eval loss: 3.78244153515292\n",
      "\n",
      "Learning rate: [0.0005520777307067275]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 72 complete:\n",
      "    Train loss: 3.7822707412861827\n",
      "    Eval loss: 3.7824413459524027\n",
      "\n",
      "Learning rate: [0.0005520777307067275]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 73 complete:\n",
      "    Train loss: 3.7822702894242455\n",
      "    Eval loss: 3.7824411672817044\n",
      "\n",
      "Learning rate: [0.0005520777307067275]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 74 complete:\n",
      "    Train loss: 3.7822702888829554\n",
      "    Eval loss: 3.782441035600883\n",
      "\n",
      "Learning rate: [0.0005520777307067275]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 75 complete:\n",
      "    Train loss: 3.782269877885513\n",
      "    Eval loss: 3.7824411368727224\n",
      "\n",
      "Learning rate: [0.0005244738441713911]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 75\n",
      "\n",
      "Epoch 76 complete:\n",
      "    Train loss: 3.782268192306269\n",
      "    Eval loss: 3.7824412040047117\n",
      "\n",
      "Learning rate: [0.0004982501519628216]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 77 complete:\n",
      "    Train loss: 3.782267119013727\n",
      "    Eval loss: 3.7824403149319212\n",
      "\n",
      "Learning rate: [0.0004982501519628216]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 78 complete:\n",
      "    Train loss: 3.782266408800962\n",
      "    Eval loss: 3.7824391701262274\n",
      "\n",
      "Learning rate: [0.0004982501519628216]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 79 complete:\n",
      "    Train loss: 3.782266322920321\n",
      "    Eval loss: 3.7824389783050614\n",
      "\n",
      "Learning rate: [0.0004982501519628216]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 80 complete:\n",
      "    Train loss: 3.782266254727337\n",
      "    Eval loss: 3.7824396691491984\n",
      "\n",
      "Learning rate: [0.0004733376443646804]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 80\n",
      "\n",
      "Epoch 81 complete:\n",
      "    Train loss: 3.782264523727884\n",
      "    Eval loss: 3.782438290974721\n",
      "\n",
      "Learning rate: [0.0004733376443646804]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 82 complete:\n",
      "    Train loss: 3.782264272141768\n",
      "    Eval loss: 3.7824387113692888\n",
      "\n",
      "Learning rate: [0.00044967076214644637]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 83 complete:\n",
      "    Train loss: 3.7822629693623027\n",
      "    Eval loss: 3.782436410488301\n",
      "\n",
      "Learning rate: [0.00044967076214644637]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 84 complete:\n",
      "    Train loss: 3.78226274403566\n",
      "    Eval loss: 3.782437527310942\n",
      "\n",
      "Learning rate: [0.00042718722403912405]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 85 complete:\n",
      "    Train loss: 3.782261269586002\n",
      "    Eval loss: 3.782437067614961\n",
      "\n",
      "Learning rate: [0.0004058278628371678]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 85\n",
      "\n",
      "Epoch 86 complete:\n",
      "    Train loss: 3.7822597744206976\n",
      "    Eval loss: 3.7824370027687007\n",
      "\n",
      "Learning rate: [0.0003855364696953094]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 87 complete:\n",
      "    Train loss: 3.7822585542909315\n",
      "    Eval loss: 3.7824361996223987\n",
      "\n",
      "Learning rate: [0.0003855364696953094]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 88 complete:\n",
      "    Train loss: 3.782258222532143\n",
      "    Eval loss: 3.78243522237188\n",
      "\n",
      "Learning rate: [0.0003855364696953094]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 89 complete:\n",
      "    Train loss: 3.7822579145056943\n",
      "    Eval loss: 3.782435752105281\n",
      "\n",
      "Learning rate: [0.0003662596462105439]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 90 complete:\n",
      "    Train loss: 3.7822565719920016\n",
      "    Eval loss: 3.7824348706808832\n",
      "\n",
      "Learning rate: [0.0003662596462105439]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 90\n",
      "\n",
      "Epoch 91 complete:\n",
      "    Train loss: 3.782256296313036\n",
      "    Eval loss: 3.782434865880296\n",
      "\n",
      "Learning rate: [0.0003662596462105439]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 92 complete:\n",
      "    Train loss: 3.7822562868462115\n",
      "    Eval loss: 3.782435865527123\n",
      "\n",
      "Learning rate: [0.0003479466639000167]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 93 complete:\n",
      "    Train loss: 3.7822549749743106\n",
      "    Eval loss: 3.7824339875808684\n",
      "\n",
      "Learning rate: [0.0003479466639000167]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 94 complete:\n",
      "    Train loss: 3.7822546401246524\n",
      "    Eval loss: 3.7824341211515575\n",
      "\n",
      "Learning rate: [0.00033054933070501586]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 95 complete:\n",
      "    Train loss: 3.7822536997603002\n",
      "    Eval loss: 3.7824335728785976\n",
      "\n",
      "Learning rate: [0.00033054933070501586]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 95\n",
      "\n",
      "Epoch 96 complete:\n",
      "    Train loss: 3.7822533326843657\n",
      "    Eval loss: 3.782433546574918\n",
      "\n",
      "Learning rate: [0.00033054933070501586]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 97 complete:\n",
      "    Train loss: 3.782253279673919\n",
      "    Eval loss: 3.782432945726697\n",
      "\n",
      "Learning rate: [0.00033054933070501586]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 98 complete:\n",
      "    Train loss: 3.7822530503579856\n",
      "    Eval loss: 3.7824330021005\n",
      "\n",
      "Learning rate: [0.00031402186416976504]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 99 complete:\n",
      "    Train loss: 3.782252100068794\n",
      "    Eval loss: 3.782431525369891\n",
      "\n",
      "Learning rate: [0.00031402186416976504]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 100 complete:\n",
      "    Train loss: 3.782251908272001\n",
      "    Eval loss: 3.782432354913203\n",
      "\n",
      "Learning rate: [0.0002983207709612768]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 100\n",
      "\n",
      "Epoch 101 complete:\n",
      "    Train loss: 3.7822509925619636\n",
      "    Eval loss: 3.7824303630890888\n",
      "\n",
      "Learning rate: [0.0002983207709612768]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 102 complete:\n",
      "    Train loss: 3.782250721117686\n",
      "    Eval loss: 3.7824299036383913\n",
      "\n",
      "Learning rate: [0.0002983207709612768]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 103 complete:\n",
      "    Train loss: 3.7822505793086965\n",
      "    Eval loss: 3.7824302727961365\n",
      "\n",
      "Learning rate: [0.00028340473241321294]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 104 complete:\n",
      "    Train loss: 3.782249683701724\n",
      "    Eval loss: 3.782428755750456\n",
      "\n",
      "Learning rate: [0.00028340473241321294]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 105 complete:\n",
      "    Train loss: 3.7822494339298154\n",
      "    Eval loss: 3.782429025378743\n",
      "\n",
      "Learning rate: [0.0002692344957925523]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 105\n",
      "\n",
      "Epoch 106 complete:\n",
      "    Train loss: 3.7822486413790095\n",
      "    Eval loss: 3.7824273087633853\n",
      "\n",
      "Learning rate: [0.0002692344957925523]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 107 complete:\n",
      "    Train loss: 3.7822484927472746\n",
      "    Eval loss: 3.7824276352112136\n",
      "\n",
      "Learning rate: [0.0002557727710029247]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 108 complete:\n",
      "    Train loss: 3.7822476995820646\n",
      "    Eval loss: 3.782426801835636\n",
      "\n",
      "Learning rate: [0.0002557727710029247]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 109 complete:\n",
      "    Train loss: 3.782247508414552\n",
      "    Eval loss: 3.7824266092631014\n",
      "\n",
      "Learning rate: [0.0002557727710029247]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 110 complete:\n",
      "    Train loss: 3.7822472813776913\n",
      "    Eval loss: 3.782426884624954\n",
      "\n",
      "Learning rate: [0.00024298413245277842]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 110\n",
      "\n",
      "Epoch 111 complete:\n",
      "    Train loss: 3.782246522976905\n",
      "    Eval loss: 3.7824259785014087\n",
      "\n",
      "Learning rate: [0.00024298413245277842]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 112 complete:\n",
      "    Train loss: 3.782246408429115\n",
      "    Eval loss: 3.782425784578275\n",
      "\n",
      "Learning rate: [0.00024298413245277842]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 113 complete:\n",
      "    Train loss: 3.782246316550313\n",
      "    Eval loss: 3.782426012838686\n",
      "\n",
      "Learning rate: [0.0002308349258301395]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 114 complete:\n",
      "    Train loss: 3.7822456023440547\n",
      "    Eval loss: 3.7824252509555607\n",
      "\n",
      "Learning rate: [0.0002308349258301395]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 115 complete:\n",
      "    Train loss: 3.782245361305617\n",
      "    Eval loss: 3.7824248719023945\n",
      "\n",
      "Learning rate: [0.0002308349258301395]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 115\n",
      "\n",
      "Epoch 116 complete:\n",
      "    Train loss: 3.7822453843298063\n",
      "    Eval loss: 3.782425125218263\n",
      "\n",
      "Learning rate: [0.0002192931795386325]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 117 complete:\n",
      "    Train loss: 3.782244603599379\n",
      "    Eval loss: 3.782424348946946\n",
      "\n",
      "Learning rate: [0.0002192931795386325]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 118 complete:\n",
      "    Train loss: 3.78224443955193\n",
      "    Eval loss: 3.782424097947792\n",
      "\n",
      "Learning rate: [0.0002192931795386325]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 119 complete:\n",
      "    Train loss: 3.7822443629751232\n",
      "    Eval loss: 3.7824239721319604\n",
      "\n",
      "Learning rate: [0.0002192931795386325]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 120 complete:\n",
      "    Train loss: 3.782244239569731\n",
      "    Eval loss: 3.7824239505113697\n",
      "\n",
      "Learning rate: [0.0002192931795386325]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 120\n",
      "\n",
      "Epoch 121 complete:\n",
      "    Train loss: 3.78224414710476\n",
      "    Eval loss: 3.782423975810531\n",
      "\n",
      "Learning rate: [0.00020832852056170087]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 122 complete:\n",
      "    Train loss: 3.7822434574928967\n",
      "    Eval loss: 3.782423007389298\n",
      "\n",
      "Learning rate: [0.00020832852056170087]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 123 complete:\n",
      "    Train loss: 3.7822433257009687\n",
      "    Eval loss: 3.7824230936705994\n",
      "\n",
      "Learning rate: [0.0001979120945336158]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 124 complete:\n",
      "    Train loss: 3.782242653932677\n",
      "    Eval loss: 3.7824219725185135\n",
      "\n",
      "Learning rate: [0.0001979120945336158]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 125 complete:\n",
      "    Train loss: 3.7822424745740646\n",
      "    Eval loss: 3.782422374406967\n",
      "\n",
      "Learning rate: [0.000188016489806935]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 125\n",
      "\n",
      "Epoch 126 complete:\n",
      "    Train loss: 3.782241821166418\n",
      "    Eval loss: 3.782421049201541\n",
      "\n",
      "Learning rate: [0.000188016489806935]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 127 complete:\n",
      "    Train loss: 3.7822416738514884\n",
      "    Eval loss: 3.7824213505935322\n",
      "\n",
      "Learning rate: [0.00017861566531658825]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 128 complete:\n",
      "    Train loss: 3.7822411197325776\n",
      "    Eval loss: 3.7824200347598773\n",
      "\n",
      "Learning rate: [0.00017861566531658825]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 129 complete:\n",
      "    Train loss: 3.782240983935533\n",
      "    Eval loss: 3.782420412460312\n",
      "\n",
      "Learning rate: [0.00016968488205075882]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 130 complete:\n",
      "    Train loss: 3.7822403831849964\n",
      "    Eval loss: 3.7824197091977716\n",
      "\n",
      "Learning rate: [0.00016968488205075882]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 130\n",
      "\n",
      "Epoch 131 complete:\n",
      "    Train loss: 3.7822402862719304\n",
      "    Eval loss: 3.7824194200165033\n",
      "\n",
      "Learning rate: [0.00016968488205075882]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 132 complete:\n",
      "    Train loss: 3.782240154096727\n",
      "    Eval loss: 3.7824194186097198\n",
      "\n",
      "Learning rate: [0.00016968488205075882]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 133 complete:\n",
      "    Train loss: 3.782240107846533\n",
      "    Eval loss: 3.7824193754638595\n",
      "\n",
      "Learning rate: [0.00016968488205075882]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 134 complete:\n",
      "    Train loss: 3.7822400284348583\n",
      "    Eval loss: 3.782419522141957\n",
      "\n",
      "Learning rate: [0.00016120063794822088]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 135 complete:\n",
      "    Train loss: 3.7822395570354277\n",
      "    Eval loss: 3.7824188244154002\n",
      "\n",
      "Learning rate: [0.00016120063794822088]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 135\n",
      "\n",
      "Epoch 136 complete:\n",
      "    Train loss: 3.7822394175065983\n",
      "    Eval loss: 3.782418487173343\n",
      "\n",
      "Learning rate: [0.00016120063794822088]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 137 complete:\n",
      "    Train loss: 3.7822394132412627\n",
      "    Eval loss: 3.7824183361349006\n",
      "\n",
      "Learning rate: [0.00016120063794822088]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 138 complete:\n",
      "    Train loss: 3.7822393250271613\n",
      "    Eval loss: 3.782418676246781\n",
      "\n",
      "Learning rate: [0.0001531406060508098]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 139 complete:\n",
      "    Train loss: 3.7822388392439947\n",
      "    Eval loss: 3.7824181428644716\n",
      "\n",
      "Learning rate: [0.0001531406060508098]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 140 complete:\n",
      "    Train loss: 3.782238737245468\n",
      "    Eval loss: 3.78241788365714\n",
      "\n",
      "Learning rate: [0.0001531406060508098]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 140\n",
      "\n",
      "Epoch 141 complete:\n",
      "    Train loss: 3.782238697368496\n",
      "    Eval loss: 3.782417923890376\n",
      "\n",
      "Learning rate: [0.0001454835757482693]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 142 complete:\n",
      "    Train loss: 3.782238130247821\n",
      "    Eval loss: 3.7824176244634464\n",
      "\n",
      "Learning rate: [0.0001454835757482693]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 143 complete:\n",
      "    Train loss: 3.7822379702341906\n",
      "    Eval loss: 3.7824177149368077\n",
      "\n",
      "Learning rate: [0.00013820939696085585]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 144 complete:\n",
      "    Train loss: 3.782237525699366\n",
      "    Eval loss: 3.782417054731553\n",
      "\n",
      "Learning rate: [0.00013820939696085585]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 145 complete:\n",
      "    Train loss: 3.782237344274889\n",
      "    Eval loss: 3.782417128738834\n",
      "\n",
      "Learning rate: [0.00013129892711281305]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 145\n",
      "\n",
      "Epoch 146 complete:\n",
      "    Train loss: 3.782236535165662\n",
      "    Eval loss: 3.7824164769244604\n",
      "\n",
      "Learning rate: [0.00013129892711281305]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 147 complete:\n",
      "    Train loss: 3.782236226941086\n",
      "    Eval loss: 3.782416382413762\n",
      "\n",
      "Learning rate: [0.00013129892711281305]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 148 complete:\n",
      "    Train loss: 3.7822360320945814\n",
      "    Eval loss: 3.7824166234159695\n",
      "\n",
      "Learning rate: [0.0001247339807571724]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 149 complete:\n",
      "    Train loss: 3.7822355162094126\n",
      "    Eval loss: 3.78241585689986\n",
      "\n",
      "Learning rate: [0.0001247339807571724]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 150 complete:\n",
      "    Train loss: 3.78223532373213\n",
      "    Eval loss: 3.782415951619622\n",
      "\n",
      "Learning rate: [0.00011849728171931376]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 150\n",
      "\n",
      "Epoch 151 complete:\n",
      "    Train loss: 3.78223474189894\n",
      "    Eval loss: 3.7824155246978126\n",
      "\n",
      "Learning rate: [0.00011849728171931376]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 152 complete:\n",
      "    Train loss: 3.7822345424070045\n",
      "    Eval loss: 3.7824154459019477\n",
      "\n",
      "Learning rate: [0.00011849728171931376]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 153 complete:\n",
      "    Train loss: 3.782234399737861\n",
      "    Eval loss: 3.782415450401212\n",
      "\n",
      "Learning rate: [0.00011257241763334806]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 154 complete:\n",
      "    Train loss: 3.782233944750774\n",
      "    Eval loss: 3.7824151231010728\n",
      "\n",
      "Learning rate: [0.00011257241763334806]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 155 complete:\n",
      "    Train loss: 3.78223371122594\n",
      "    Eval loss: 3.7824152024070465\n",
      "\n",
      "Learning rate: [0.00010694379675168066]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 155\n",
      "\n",
      "Epoch 156 complete:\n",
      "    Train loss: 3.782233262013821\n",
      "    Eval loss: 3.782414762018793\n",
      "\n",
      "Learning rate: [0.00010694379675168066]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 157 complete:\n",
      "    Train loss: 3.7822330565243667\n",
      "    Eval loss: 3.7824149268193787\n",
      "\n",
      "Learning rate: [0.00010159660691409662]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 158 complete:\n",
      "    Train loss: 3.782232616145298\n",
      "    Eval loss: 3.7824145012902464\n",
      "\n",
      "Learning rate: [0.00010159660691409662]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 159 complete:\n",
      "    Train loss: 3.7822324271454053\n",
      "    Eval loss: 3.78241447265425\n",
      "\n",
      "Learning rate: [0.00010159660691409662]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 160 complete:\n",
      "    Train loss: 3.7822322605528873\n",
      "    Eval loss: 3.7824145809549528\n",
      "\n",
      "Learning rate: [9.65167765683918e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 160\n",
      "\n",
      "Epoch 161 complete:\n",
      "    Train loss: 3.782231858968105\n",
      "    Eval loss: 3.7824142892502874\n",
      "\n",
      "Learning rate: [9.65167765683918e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 162 complete:\n",
      "    Train loss: 3.782231692693937\n",
      "    Eval loss: 3.782414268550252\n",
      "\n",
      "Learning rate: [9.65167765683918e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 163 complete:\n",
      "    Train loss: 3.7822315656760512\n",
      "    Eval loss: 3.7824141419235335\n",
      "\n",
      "Learning rate: [9.65167765683918e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 164 complete:\n",
      "    Train loss: 3.7822314575869718\n",
      "    Eval loss: 3.782414158121611\n",
      "\n",
      "Learning rate: [9.16909377399722e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 165 complete:\n",
      "    Train loss: 3.782231065025952\n",
      "    Eval loss: 3.7824138746153895\n",
      "\n",
      "Learning rate: [9.16909377399722e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 165\n",
      "\n",
      "Epoch 166 complete:\n",
      "    Train loss: 3.7822309033362482\n",
      "    Eval loss: 3.7824138728839545\n",
      "\n",
      "Learning rate: [9.16909377399722e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 167 complete:\n",
      "    Train loss: 3.7822307913856408\n",
      "    Eval loss: 3.782413897738051\n",
      "\n",
      "Learning rate: [8.710639085297359e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 168 complete:\n",
      "    Train loss: 3.782230371326703\n",
      "    Eval loss: 3.7824136858985224\n",
      "\n",
      "Learning rate: [8.710639085297359e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 169 complete:\n",
      "    Train loss: 3.7822302154001624\n",
      "    Eval loss: 3.7824137043435537\n",
      "\n",
      "Learning rate: [8.275107131032491e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 170 complete:\n",
      "    Train loss: 3.7822298771288945\n",
      "    Eval loss: 3.7824135669171715\n",
      "\n",
      "Learning rate: [8.275107131032491e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 170\n",
      "\n",
      "Epoch 171 complete:\n",
      "    Train loss: 3.782229752630391\n",
      "    Eval loss: 3.7824136673133575\n",
      "\n",
      "Learning rate: [7.861351774480866e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 172 complete:\n",
      "    Train loss: 3.7822294211673664\n",
      "    Eval loss: 3.7824133501948953\n",
      "\n",
      "Learning rate: [7.861351774480866e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 173 complete:\n",
      "    Train loss: 3.7822292841568146\n",
      "    Eval loss: 3.7824132847267813\n",
      "\n",
      "Learning rate: [7.861351774480866e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 174 complete:\n",
      "    Train loss: 3.7822291892303412\n",
      "    Eval loss: 3.7824132818385774\n",
      "\n",
      "Learning rate: [7.861351774480866e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 175 complete:\n",
      "    Train loss: 3.7822291202743368\n",
      "    Eval loss: 3.7824133676954617\n",
      "\n",
      "Learning rate: [7.468284185756822e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 175\n",
      "\n",
      "Epoch 176 complete:\n",
      "    Train loss: 3.782228793332155\n",
      "    Eval loss: 3.7824132140476143\n",
      "\n",
      "Learning rate: [7.468284185756822e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 177 complete:\n",
      "    Train loss: 3.782228683893474\n",
      "    Eval loss: 3.7824131573665025\n",
      "\n",
      "Learning rate: [7.468284185756822e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 178 complete:\n",
      "    Train loss: 3.7822286276561883\n",
      "    Eval loss: 3.782413112860683\n",
      "\n",
      "Learning rate: [7.468284185756822e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 179 complete:\n",
      "    Train loss: 3.782228546100359\n",
      "    Eval loss: 3.7824131617854344\n",
      "\n",
      "Learning rate: [7.094869976468981e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 180 complete:\n",
      "    Train loss: 3.7822282332083574\n",
      "    Eval loss: 3.782413098336251\n",
      "\n",
      "Learning rate: [7.094869976468981e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 180\n",
      "\n",
      "Epoch 181 complete:\n",
      "    Train loss: 3.7822281133894053\n",
      "    Eval loss: 3.782413141900308\n",
      "\n",
      "Learning rate: [6.740126477645532e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 182 complete:\n",
      "    Train loss: 3.7822278298504353\n",
      "    Eval loss: 3.782412983692187\n",
      "\n",
      "Learning rate: [6.740126477645532e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 183 complete:\n",
      "    Train loss: 3.78222774483163\n",
      "    Eval loss: 3.7824130241702845\n",
      "\n",
      "Learning rate: [6.403120153763255e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 184 complete:\n",
      "    Train loss: 3.7822274339772024\n",
      "    Eval loss: 3.7824128556010486\n",
      "\n",
      "Learning rate: [6.403120153763255e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 185 complete:\n",
      "    Train loss: 3.7822273273528917\n",
      "    Eval loss: 3.7824128468044993\n",
      "\n",
      "Learning rate: [6.403120153763255e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 185\n",
      "\n",
      "Epoch 186 complete:\n",
      "    Train loss: 3.782227269213586\n",
      "    Eval loss: 3.7824129570848113\n",
      "\n",
      "Learning rate: [6.082964146075092e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 187 complete:\n",
      "    Train loss: 3.7822270252225403\n",
      "    Eval loss: 3.782412918757099\n",
      "\n",
      "Learning rate: [5.778815938771337e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 188 complete:\n",
      "    Train loss: 3.782226736603962\n",
      "    Eval loss: 3.782412837087475\n",
      "\n",
      "Learning rate: [5.778815938771337e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 189 complete:\n",
      "    Train loss: 3.782226658592801\n",
      "    Eval loss: 3.7824128679979987\n",
      "\n",
      "Learning rate: [5.48987514183277e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 190 complete:\n",
      "    Train loss: 3.7822264105702317\n",
      "    Eval loss: 3.7824127778993697\n",
      "\n",
      "Learning rate: [5.48987514183277e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 190\n",
      "\n",
      "Epoch 191 complete:\n",
      "    Train loss: 3.7822263287249824\n",
      "    Eval loss: 3.7824128042301375\n",
      "\n",
      "Learning rate: [5.215381384741131e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 192 complete:\n",
      "    Train loss: 3.7822260631253775\n",
      "    Eval loss: 3.782412731802928\n",
      "\n",
      "Learning rate: [5.215381384741131e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 193 complete:\n",
      "    Train loss: 3.782225998535098\n",
      "    Eval loss: 3.7824127377888437\n",
      "\n",
      "Learning rate: [4.954612315504074e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 194 complete:\n",
      "    Train loss: 3.7822257603952467\n",
      "    Eval loss: 3.782412676824101\n",
      "\n",
      "Learning rate: [4.954612315504074e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 195 complete:\n",
      "    Train loss: 3.782225701290639\n",
      "    Eval loss: 3.782412718236758\n",
      "\n",
      "Learning rate: [4.70688169972887e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 195\n",
      "\n",
      "Epoch 196 complete:\n",
      "    Train loss: 3.7822254708764813\n",
      "    Eval loss: 3.7824126438184082\n",
      "\n",
      "Learning rate: [4.70688169972887e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 197 complete:\n",
      "    Train loss: 3.7822254052266415\n",
      "    Eval loss: 3.7824126896919723\n",
      "\n",
      "Learning rate: [4.4715376147424265e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 198 complete:\n",
      "    Train loss: 3.7822252030858685\n",
      "    Eval loss: 3.7824126799121807\n",
      "\n",
      "Learning rate: [4.247960734005305e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 199 complete:\n",
      "    Train loss: 3.7822249696058328\n",
      "    Eval loss: 3.7824126324557397\n",
      "\n",
      "Learning rate: [4.247960734005305e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 200 complete:\n",
      "    Train loss: 3.782224908788095\n",
      "    Eval loss: 3.7824126844595147\n",
      "\n",
      "Learning rate: [4.03556269730504e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 200\n",
      "\n",
      "Epoch 201 complete:\n",
      "    Train loss: 3.782224704157122\n",
      "    Eval loss: 3.7824126845554815\n",
      "\n",
      "Learning rate: [3.833784562439787e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 202 complete:\n",
      "    Train loss: 3.782224497499636\n",
      "    Eval loss: 3.7824125918314433\n",
      "\n",
      "Learning rate: [3.833784562439787e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 203 complete:\n",
      "    Train loss: 3.782224440153423\n",
      "    Eval loss: 3.7824125928187238\n",
      "\n",
      "Learning rate: [3.6420953343177974e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 204 complete:\n",
      "    Train loss: 3.782224249359119\n",
      "    Eval loss: 3.7824125630758365\n",
      "\n",
      "Learning rate: [3.6420953343177974e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 205 complete:\n",
      "    Train loss: 3.782224205003223\n",
      "    Eval loss: 3.78241258982506\n",
      "\n",
      "Learning rate: [3.4599905676019076e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 205\n",
      "\n",
      "Epoch 206 complete:\n",
      "    Train loss: 3.7822240207719764\n",
      "    Eval loss: 3.7824125672307147\n",
      "\n",
      "Learning rate: [3.286991039221812e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 207 complete:\n",
      "    Train loss: 3.782223847500738\n",
      "    Eval loss: 3.7824125110645297\n",
      "\n",
      "Learning rate: [3.286991039221812e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 208 complete:\n",
      "    Train loss: 3.7822237966857357\n",
      "    Eval loss: 3.782412535608469\n",
      "\n",
      "Learning rate: [3.122641487260721e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 209 complete:\n",
      "    Train loss: 3.782223641057617\n",
      "    Eval loss: 3.7824125039117544\n",
      "\n",
      "Learning rate: [3.122641487260721e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 210 complete:\n",
      "    Train loss: 3.782223591487828\n",
      "    Eval loss: 3.7824125045122647\n",
      "\n",
      "Learning rate: [2.9665094128976848e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 210\n",
      "\n",
      "Epoch 211 complete:\n",
      "    Train loss: 3.782223436901599\n",
      "    Eval loss: 3.7824125055622577\n",
      "\n",
      "Learning rate: [2.8181839422528005e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 212 complete:\n",
      "    Train loss: 3.782223289078179\n",
      "    Eval loss: 3.782412475605464\n",
      "\n",
      "Learning rate: [2.8181839422528005e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 213 complete:\n",
      "    Train loss: 3.782223245878422\n",
      "    Eval loss: 3.782412471907913\n",
      "\n",
      "Learning rate: [2.8181839422528005e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 214 complete:\n",
      "    Train loss: 3.782223213612166\n",
      "    Eval loss: 3.7824124678530975\n",
      "\n",
      "Learning rate: [2.8181839422528005e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 215 complete:\n",
      "    Train loss: 3.7822231911206114\n",
      "    Eval loss: 3.782412481611916\n",
      "\n",
      "Learning rate: [2.6772747451401602e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 215\n",
      "\n",
      "Epoch 216 complete:\n",
      "    Train loss: 3.7822230501076994\n",
      "    Eval loss: 3.782412477728574\n",
      "\n",
      "Learning rate: [2.5434110078831522e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 217 complete:\n",
      "    Train loss: 3.782222907940871\n",
      "    Eval loss: 3.782412445792854\n",
      "\n",
      "Learning rate: [2.5434110078831522e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 218 complete:\n",
      "    Train loss: 3.7822228654323156\n",
      "    Eval loss: 3.7824124659410048\n",
      "\n",
      "Learning rate: [2.4162404574889944e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 219 complete:\n",
      "    Train loss: 3.782222732073664\n",
      "    Eval loss: 3.782412428587457\n",
      "\n",
      "Learning rate: [2.4162404574889944e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 220 complete:\n",
      "    Train loss: 3.782222709802744\n",
      "    Eval loss: 3.7824124451105225\n",
      "\n",
      "Learning rate: [2.2954284346145446e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 220\n",
      "\n",
      "Epoch 221 complete:\n",
      "    Train loss: 3.782222585086749\n",
      "    Eval loss: 3.782412441980952\n",
      "\n",
      "Learning rate: [2.1806570128838174e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 222 complete:\n",
      "    Train loss: 3.782222461390285\n",
      "    Eval loss: 3.782412433612853\n",
      "\n",
      "Learning rate: [2.0716241622396264e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 223 complete:\n",
      "    Train loss: 3.782222338213853\n",
      "    Eval loss: 3.782412455420892\n",
      "\n",
      "Learning rate: [1.968042954127645e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 224 complete:\n",
      "    Train loss: 3.782222221188343\n",
      "    Eval loss: 3.7824123913318246\n",
      "\n",
      "Learning rate: [1.968042954127645e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 225 complete:\n",
      "    Train loss: 3.7822221897586137\n",
      "    Eval loss: 3.7824123943607995\n",
      "\n",
      "Learning rate: [1.8696408064212627e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 225\n",
      "\n",
      "Epoch 226 complete:\n",
      "    Train loss: 3.782222082850412\n",
      "    Eval loss: 3.7824123778182828\n",
      "\n",
      "Learning rate: [1.8696408064212627e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 227 complete:\n",
      "    Train loss: 3.782222061162387\n",
      "    Eval loss: 3.7824123730759114\n",
      "\n",
      "Learning rate: [1.8696408064212627e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 228 complete:\n",
      "    Train loss: 3.7822220404473317\n",
      "    Eval loss: 3.782412380360096\n",
      "\n",
      "Learning rate: [1.7761587661001995e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 229 complete:\n",
      "    Train loss: 3.7822219369331833\n",
      "    Eval loss: 3.782412334387377\n",
      "\n",
      "Learning rate: [1.7761587661001995e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 230 complete:\n",
      "    Train loss: 3.7822219162326247\n",
      "    Eval loss: 3.7824123396067346\n",
      "\n",
      "Learning rate: [1.6873508277951895e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 230\n",
      "\n",
      "Epoch 231 complete:\n",
      "    Train loss: 3.7822218210788603\n",
      "    Eval loss: 3.782412311904786\n",
      "\n",
      "Learning rate: [1.6873508277951895e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 232 complete:\n",
      "    Train loss: 3.7822218003159542\n",
      "    Eval loss: 3.7824123065136157\n",
      "\n",
      "Learning rate: [1.6873508277951895e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 233 complete:\n",
      "    Train loss: 3.782221780056975\n",
      "    Eval loss: 3.782412328589594\n",
      "\n",
      "Learning rate: [1.60298328640543e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 234 complete:\n",
      "    Train loss: 3.7822216881866813\n",
      "    Eval loss: 3.7824123215740766\n",
      "\n",
      "Learning rate: [1.5228341220851583e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 235 complete:\n",
      "    Train loss: 3.782221595330927\n",
      "    Eval loss: 3.7824123086312165\n",
      "\n",
      "Learning rate: [1.4466924159809002e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 235\n",
      "\n",
      "Epoch 236 complete:\n",
      "    Train loss: 3.782221507737774\n",
      "    Eval loss: 3.7824122985476296\n",
      "\n",
      "Learning rate: [1.4466924159809002e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 237 complete:\n",
      "    Train loss: 3.782221490643166\n",
      "    Eval loss: 3.7824123046470124\n",
      "\n",
      "Learning rate: [1.3743577951818552e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 238 complete:\n",
      "    Train loss: 3.782221413533371\n",
      "    Eval loss: 3.782412303830101\n",
      "\n",
      "Learning rate: [1.3056399054227623e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 239 complete:\n",
      "    Train loss: 3.782221331755172\n",
      "    Eval loss: 3.782412302186628\n",
      "\n",
      "Learning rate: [1.2403579101516242e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 240 complete:\n",
      "    Train loss: 3.7822212534777453\n",
      "    Eval loss: 3.7824122850944044\n",
      "\n",
      "Learning rate: [1.2403579101516242e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 240\n",
      "\n",
      "Epoch 241 complete:\n",
      "    Train loss: 3.7822212369892214\n",
      "    Eval loss: 3.7824122964389595\n",
      "\n",
      "Learning rate: [1.178340014644043e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 242 complete:\n",
      "    Train loss: 3.782221165128011\n",
      "    Eval loss: 3.782412293080385\n",
      "\n",
      "Learning rate: [1.1194230139118406e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 243 complete:\n",
      "    Train loss: 3.7822210921842134\n",
      "    Eval loss: 3.7824122829216638\n",
      "\n",
      "Learning rate: [1.1194230139118406e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 244 complete:\n",
      "    Train loss: 3.7822210775724328\n",
      "    Eval loss: 3.7824122862834764\n",
      "\n",
      "Learning rate: [1.0634518632162485e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 245 complete:\n",
      "    Train loss: 3.782221010769498\n",
      "    Eval loss: 3.7824122789710395\n",
      "\n",
      "Learning rate: [1.0634518632162485e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 245\n",
      "\n",
      "Epoch 246 complete:\n",
      "    Train loss: 3.782220997235665\n",
      "    Eval loss: 3.782412291635549\n",
      "\n",
      "Learning rate: [1.010279270055436e-05]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 247 complete:\n",
      "    Train loss: 3.7822209349446485\n",
      "    Eval loss: 3.782412281791486\n",
      "\n",
      "Learning rate: [9.597653065526641e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 248 complete:\n",
      "    Train loss: 3.7822208782685736\n",
      "    Eval loss: 3.782412267387152\n",
      "\n",
      "Learning rate: [9.597653065526641e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 249 complete:\n",
      "    Train loss: 3.7822208658367655\n",
      "    Eval loss: 3.7824122743556465\n",
      "\n",
      "Learning rate: [9.11777041225031e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 250 complete:\n",
      "    Train loss: 3.782220810492173\n",
      "    Eval loss: 3.7824122717414927\n",
      "\n",
      "Learning rate: [8.661881891637793e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 250\n",
      "\n",
      "Epoch 251 complete:\n",
      "    Train loss: 3.7822207557499268\n",
      "    Eval loss: 3.7824122649015086\n",
      "\n",
      "Learning rate: [8.661881891637793e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 252 complete:\n",
      "    Train loss: 3.782220745105717\n",
      "    Eval loss: 3.7824122643696323\n",
      "\n",
      "Learning rate: [8.661881891637793e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 253 complete:\n",
      "    Train loss: 3.782220736850312\n",
      "    Eval loss: 3.7824122662970505\n",
      "\n",
      "Learning rate: [8.228787797055902e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 254 complete:\n",
      "    Train loss: 3.782220686421514\n",
      "    Eval loss: 3.782412267799368\n",
      "\n",
      "Learning rate: [7.817348407203107e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 255 complete:\n",
      "    Train loss: 3.782220637846852\n",
      "    Eval loss: 3.782412262056465\n",
      "\n",
      "Learning rate: [7.817348407203107e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 255\n",
      "\n",
      "Epoch 256 complete:\n",
      "    Train loss: 3.782220627893376\n",
      "    Eval loss: 3.782412263639425\n",
      "\n",
      "Learning rate: [7.426480986842951e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 257 complete:\n",
      "    Train loss: 3.7822205812708156\n",
      "    Eval loss: 3.78241226660786\n",
      "\n",
      "Learning rate: [7.055156937500804e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 258 complete:\n",
      "    Train loss: 3.7822205358081633\n",
      "    Eval loss: 3.782412267008672\n",
      "\n",
      "Learning rate: [6.702399090625764e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 259 complete:\n",
      "    Train loss: 3.7822204926653815\n",
      "    Eval loss: 3.7824122639504285\n",
      "\n",
      "Learning rate: [6.367279136094475e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 260 complete:\n",
      "    Train loss: 3.7822204512442155\n",
      "    Eval loss: 3.7824122637564357\n",
      "\n",
      "Learning rate: [6.048915179289751e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 260\n",
      "\n",
      "Epoch 261 complete:\n",
      "    Train loss: 3.782220412295137\n",
      "    Eval loss: 3.7824122629552472\n",
      "\n",
      "Learning rate: [5.746469420325264e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 262 complete:\n",
      "    Train loss: 3.7822203752062995\n",
      "    Eval loss: 3.7824122615090814\n",
      "\n",
      "Learning rate: [5.746469420325264e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 263 complete:\n",
      "    Train loss: 3.7822203685587916\n",
      "    Eval loss: 3.7824122603945587\n",
      "\n",
      "Learning rate: [5.746469420325264e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 264 complete:\n",
      "    Train loss: 3.7822203637585994\n",
      "    Eval loss: 3.78241225916237\n",
      "\n",
      "Learning rate: [5.746469420325264e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 265 complete:\n",
      "    Train loss: 3.7822203574773505\n",
      "    Eval loss: 3.782412259799144\n",
      "\n",
      "Learning rate: [5.459145949309e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 265\n",
      "\n",
      "Epoch 266 complete:\n",
      "    Train loss: 3.782220323663033\n",
      "    Eval loss: 3.7824122599527072\n",
      "\n",
      "Learning rate: [5.18618865184355e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 267 complete:\n",
      "    Train loss: 3.7822202901658137\n",
      "    Eval loss: 3.782412261464311\n",
      "\n",
      "Learning rate: [4.926879219251373e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 268 complete:\n",
      "    Train loss: 3.782220257028858\n",
      "    Eval loss: 3.782412259959779\n",
      "\n",
      "Learning rate: [4.680535258288804e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 269 complete:\n",
      "    Train loss: 3.7822202260038944\n",
      "    Eval loss: 3.7824122637358486\n",
      "\n",
      "Learning rate: [4.446508495374363e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 270 complete:\n",
      "    Train loss: 3.7822201962088875\n",
      "    Eval loss: 3.7824122602962587\n",
      "\n",
      "Learning rate: [4.224183070605645e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 270\n",
      "\n",
      "Epoch 271 complete:\n",
      "    Train loss: 3.782220167816921\n",
      "    Eval loss: 3.782412261713765\n",
      "\n",
      "Learning rate: [4.012973917075362e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 272 complete:\n",
      "    Train loss: 3.7822201410977296\n",
      "    Eval loss: 3.7824122583363375\n",
      "\n",
      "Learning rate: [4.012973917075362e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 273 complete:\n",
      "    Train loss: 3.782220136926855\n",
      "    Eval loss: 3.7824122585311697\n",
      "\n",
      "Learning rate: [3.812325221221594e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 274 complete:\n",
      "    Train loss: 3.7822201117319625\n",
      "    Eval loss: 3.78241226034338\n",
      "\n",
      "Learning rate: [3.621708960160514e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 275 complete:\n",
      "    Train loss: 3.7822200873306278\n",
      "    Eval loss: 3.7824122624983807\n",
      "\n",
      "Learning rate: [3.440623512152488e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 275\n",
      "\n",
      "Epoch 276 complete:\n",
      "    Train loss: 3.782220064133013\n",
      "    Eval loss: 3.782412264084391\n",
      "\n",
      "Learning rate: [3.2685923365448633e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 277 complete:\n",
      "    Train loss: 3.782220042325653\n",
      "    Eval loss: 3.7824122656631856\n",
      "\n",
      "Learning rate: [3.10516271971762e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 278 complete:\n",
      "    Train loss: 3.782220021031202\n",
      "    Eval loss: 3.782412267173915\n",
      "\n",
      "Learning rate: [2.949904583731739e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 279 complete:\n",
      "    Train loss: 3.7822200011193354\n",
      "    Eval loss: 3.782412269795888\n",
      "\n",
      "Learning rate: [2.802409354545152e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 280 complete:\n",
      "    Train loss: 3.7822199823111764\n",
      "    Eval loss: 3.7824122733546512\n",
      "\n",
      "Learning rate: [2.662288886817894e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 280\n",
      "\n",
      "Epoch 281 complete:\n",
      "    Train loss: 3.7822199642962575\n",
      "    Eval loss: 3.782412275903051\n",
      "\n",
      "Learning rate: [2.5291744424769995e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 282 complete:\n",
      "    Train loss: 3.7822199471524525\n",
      "    Eval loss: 3.7824122776018663\n",
      "\n",
      "Learning rate: [2.4027157203531494e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 283 complete:\n",
      "    Train loss: 3.7822199307227633\n",
      "    Eval loss: 3.7824122770945476\n",
      "\n",
      "Learning rate: [2.2825799343354918e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 284 complete:\n",
      "    Train loss: 3.7822199156447525\n",
      "    Eval loss: 3.782412275541021\n",
      "\n",
      "Learning rate: [2.168450937618717e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 285 complete:\n",
      "    Train loss: 3.7822199009288417\n",
      "    Eval loss: 3.7824122746042934\n",
      "\n",
      "Learning rate: [2.0600283907377814e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 285\n",
      "\n",
      "Epoch 286 complete:\n",
      "    Train loss: 3.7822198870710095\n",
      "    Eval loss: 3.7824122737754076\n",
      "\n",
      "Learning rate: [1.9570269712008923e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 287 complete:\n",
      "    Train loss: 3.7822198738598836\n",
      "    Eval loss: 3.7824122736828305\n",
      "\n",
      "Learning rate: [1.8591756226408476e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 288 complete:\n",
      "    Train loss: 3.7822198612753852\n",
      "    Eval loss: 3.7824122747858593\n",
      "\n",
      "Learning rate: [1.7662168415088052e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 289 complete:\n",
      "    Train loss: 3.7822198490586674\n",
      "    Eval loss: 3.782412275154043\n",
      "\n",
      "Learning rate: [1.6779059994333648e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 290 complete:\n",
      "    Train loss: 3.782219837658833\n",
      "    Eval loss: 3.782412276100837\n",
      "\n",
      "Learning rate: [1.5940106994616965e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 290\n",
      "\n",
      "Epoch 291 complete:\n",
      "    Train loss: 3.7822198269049063\n",
      "    Eval loss: 3.7824122775759568\n",
      "\n",
      "Learning rate: [1.5143101644886117e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 292 complete:\n",
      "    Train loss: 3.7822198167189196\n",
      "    Eval loss: 3.7824122782344354\n",
      "\n",
      "Learning rate: [1.438594656264181e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 293 complete:\n",
      "    Train loss: 3.7822198069201147\n",
      "    Eval loss: 3.7824122795287085\n",
      "\n",
      "Learning rate: [1.3666649234509719e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 294 complete:\n",
      "    Train loss: 3.7822197976298884\n",
      "    Eval loss: 3.7824122805226343\n",
      "\n",
      "Learning rate: [1.2983316772784233e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 295 complete:\n",
      "    Train loss: 3.782219788732009\n",
      "    Eval loss: 3.782412281074788\n",
      "\n",
      "Learning rate: [1.233415093414502e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 295\n",
      "\n",
      "Epoch 296 complete:\n",
      "    Train loss: 3.7822197803277615\n",
      "    Eval loss: 3.7824122815841394\n",
      "\n",
      "Learning rate: [1.171744338743777e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 297 complete:\n",
      "    Train loss: 3.7822197723468562\n",
      "    Eval loss: 3.7824122821320154\n",
      "\n",
      "Learning rate: [1.113157121806588e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 298 complete:\n",
      "    Train loss: 3.7822197647188847\n",
      "    Eval loss: 3.782412282994259\n",
      "\n",
      "Learning rate: [1.0574992657162585e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 299 complete:\n",
      "    Train loss: 3.782219757490015\n",
      "    Eval loss: 3.7824122837097076\n",
      "\n",
      "Learning rate: [1.0046243024304456e-06]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 300 complete:\n",
      "    Train loss: 3.782219750629651\n",
      "    Eval loss: 3.7824122844888857\n",
      "\n",
      "Learning rate: [9.543930873089232e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 300\n",
      "\n",
      "Epoch 301 complete:\n",
      "    Train loss: 3.782219744096473\n",
      "    Eval loss: 3.782412285158937\n",
      "\n",
      "Learning rate: [9.06673432943477e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 302 complete:\n",
      "    Train loss: 3.782219737813302\n",
      "    Eval loss: 3.7824122855480495\n",
      "\n",
      "Learning rate: [8.613397612963031e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 303 complete:\n",
      "    Train loss: 3.782219731859297\n",
      "    Eval loss: 3.7824122860693117\n",
      "\n",
      "Learning rate: [8.182727732314878e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 304 complete:\n",
      "    Train loss: 3.782219726252135\n",
      "    Eval loss: 3.7824122874329347\n",
      "\n",
      "Learning rate: [7.773591345699134e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 305 complete:\n",
      "    Train loss: 3.7822197209028072\n",
      "    Eval loss: 3.782412288357054\n",
      "\n",
      "Learning rate: [7.384911778414176e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 305\n",
      "\n",
      "Epoch 306 complete:\n",
      "    Train loss: 3.7822197158245356\n",
      "    Eval loss: 3.782412289331339\n",
      "\n",
      "Learning rate: [7.015666189493467e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 307 complete:\n",
      "    Train loss: 3.782219710930908\n",
      "    Eval loss: 3.7824122901276946\n",
      "\n",
      "Learning rate: [6.664882880018793e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 308 complete:\n",
      "    Train loss: 3.782219706305427\n",
      "    Eval loss: 3.78241229072986\n",
      "\n",
      "Learning rate: [6.331638736017853e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 309 complete:\n",
      "    Train loss: 3.7822197019070423\n",
      "    Eval loss: 3.7824122915806058\n",
      "\n",
      "Learning rate: [6.01505679921696e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 310 complete:\n",
      "    Train loss: 3.782219697734715\n",
      "    Eval loss: 3.7824122922822405\n",
      "\n",
      "Learning rate: [5.714303959256111e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 310\n",
      "\n",
      "Epoch 311 complete:\n",
      "    Train loss: 3.78221969381358\n",
      "    Eval loss: 3.782412292720315\n",
      "\n",
      "Learning rate: [5.428588761293305e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 312 complete:\n",
      "    Train loss: 3.7822196900767056\n",
      "    Eval loss: 3.782412293068667\n",
      "\n",
      "Learning rate: [5.15715932322864e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 313 complete:\n",
      "    Train loss: 3.7822196865004662\n",
      "    Eval loss: 3.782412293383277\n",
      "\n",
      "Learning rate: [4.899301357067207e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 314 complete:\n",
      "    Train loss: 3.782219683100267\n",
      "    Eval loss: 3.7824122934907733\n",
      "\n",
      "Learning rate: [4.6543362892138464e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 315 complete:\n",
      "    Train loss: 3.7822196798805545\n",
      "    Eval loss: 3.7824122936632882\n",
      "\n",
      "Learning rate: [4.421619474753154e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 315\n",
      "\n",
      "Epoch 316 complete:\n",
      "    Train loss: 3.7822196768144054\n",
      "    Eval loss: 3.7824122938595375\n",
      "\n",
      "Learning rate: [4.200538501015496e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 317 complete:\n",
      "    Train loss: 3.7822196738985054\n",
      "    Eval loss: 3.7824122940657356\n",
      "\n",
      "Learning rate: [3.990511575964721e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 318 complete:\n",
      "    Train loss: 3.7822196711299285\n",
      "    Eval loss: 3.7824122940751654\n",
      "\n",
      "Learning rate: [3.790985997166485e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 319 complete:\n",
      "    Train loss: 3.7822196685036498\n",
      "    Eval loss: 3.7824122940804186\n",
      "\n",
      "Learning rate: [3.60143669730816e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 320 complete:\n",
      "    Train loss: 3.782219665994839\n",
      "    Eval loss: 3.7824122940965648\n",
      "\n",
      "Learning rate: [3.421364862442752e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 320\n",
      "\n",
      "Epoch 321 complete:\n",
      "    Train loss: 3.782219663640032\n",
      "    Eval loss: 3.782412294169139\n",
      "\n",
      "Learning rate: [3.2502966193206143e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 322 complete:\n",
      "    Train loss: 3.7822196613819554\n",
      "    Eval loss: 3.782412294365054\n",
      "\n",
      "Learning rate: [3.0877817883545835e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 323 complete:\n",
      "    Train loss: 3.782219659262874\n",
      "    Eval loss: 3.782412294623399\n",
      "\n",
      "Learning rate: [2.933392698936854e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 324 complete:\n",
      "    Train loss: 3.7822196572256703\n",
      "    Eval loss: 3.7824122948562384\n",
      "\n",
      "Learning rate: [2.786723063990011e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 325 complete:\n",
      "    Train loss: 3.7822196553066187\n",
      "    Eval loss: 3.7824122949715013\n",
      "\n",
      "Learning rate: [2.6473869107905103e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 325\n",
      "\n",
      "Epoch 326 complete:\n",
      "    Train loss: 3.782219653474015\n",
      "    Eval loss: 3.782412295001153\n",
      "\n",
      "Learning rate: [2.5150175652509845e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 327 complete:\n",
      "    Train loss: 3.7822196517304505\n",
      "    Eval loss: 3.782412294976373\n",
      "\n",
      "Learning rate: [2.389266686988435e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 328 complete:\n",
      "    Train loss: 3.782219650083548\n",
      "    Eval loss: 3.7824122948975765\n",
      "\n",
      "Learning rate: [2.269803352639013e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 329 complete:\n",
      "    Train loss: 3.7822196485126462\n",
      "    Eval loss: 3.7824122948148964\n",
      "\n",
      "Learning rate: [2.1563131850070624e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 330 complete:\n",
      "    Train loss: 3.7822196470183753\n",
      "    Eval loss: 3.7824122947183545\n",
      "\n",
      "Learning rate: [2.0484975257567092e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 330\n",
      "\n",
      "Epoch 331 complete:\n",
      "    Train loss: 3.782219645603112\n",
      "    Eval loss: 3.7824122946619823\n",
      "\n",
      "Learning rate: [1.9460726494688735e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 332 complete:\n",
      "    Train loss: 3.7822196442512257\n",
      "    Eval loss: 3.7824122945507583\n",
      "\n",
      "Learning rate: [1.8487690169954297e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 333 complete:\n",
      "    Train loss: 3.782219642971703\n",
      "    Eval loss: 3.782412294428105\n",
      "\n",
      "Learning rate: [1.7563305661456583e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 334 complete:\n",
      "    Train loss: 3.78221964175525\n",
      "    Eval loss: 3.7824122943408964\n",
      "\n",
      "Learning rate: [1.6685140378383754e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 335 complete:\n",
      "    Train loss: 3.7822196405979773\n",
      "    Eval loss: 3.782412294238337\n",
      "\n",
      "Learning rate: [1.5850883359464565e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 335\n",
      "\n",
      "Epoch 336 complete:\n",
      "    Train loss: 3.7822196395033347\n",
      "    Eval loss: 3.782412294140189\n",
      "\n",
      "Learning rate: [1.5058339191491336e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 337 complete:\n",
      "    Train loss: 3.7822196384594733\n",
      "    Eval loss: 3.782412294044003\n",
      "\n",
      "Learning rate: [1.4305422231916767e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 338 complete:\n",
      "    Train loss: 3.782219637469651\n",
      "    Eval loss: 3.7824122939614804\n",
      "\n",
      "Learning rate: [1.3590151120320929e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 339 complete:\n",
      "    Train loss: 3.782219636530149\n",
      "    Eval loss: 3.782412293888719\n",
      "\n",
      "Learning rate: [1.291064356430488e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 340 complete:\n",
      "    Train loss: 3.7822196356345983\n",
      "    Eval loss: 3.782412293870087\n",
      "\n",
      "Learning rate: [1.2265111386089638e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 340\n",
      "\n",
      "Epoch 341 complete:\n",
      "    Train loss: 3.7822196347850077\n",
      "    Eval loss: 3.782412293833373\n",
      "\n",
      "Learning rate: [1.1651855816785155e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 342 complete:\n",
      "    Train loss: 3.782219633974957\n",
      "    Eval loss: 3.782412293807938\n",
      "\n",
      "Learning rate: [1.1069263025945897e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 343 complete:\n",
      "    Train loss: 3.7822196332069047\n",
      "    Eval loss: 3.7824122938192413\n",
      "\n",
      "Learning rate: [1.0515799874648602e-07]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 344 complete:\n",
      "    Train loss: 3.782219632473499\n",
      "    Eval loss: 3.7824122938400655\n",
      "\n",
      "Learning rate: [9.990009880916172e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 345 complete:\n",
      "    Train loss: 3.782219631780177\n",
      "    Eval loss: 3.782412293850864\n",
      "\n",
      "Learning rate: [9.490509386870363e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 345\n",
      "\n",
      "Epoch 346 complete:\n",
      "    Train loss: 3.782219631122705\n",
      "    Eval loss: 3.78241229386921\n",
      "\n",
      "Learning rate: [9.015983917526845e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 347 complete:\n",
      "    Train loss: 3.7822196304962032\n",
      "    Eval loss: 3.7824122938723246\n",
      "\n",
      "Learning rate: [8.565184721650502e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 348 complete:\n",
      "    Train loss: 3.782219629901\n",
      "    Eval loss: 3.782412293870133\n",
      "\n",
      "Learning rate: [8.136925485567976e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 349 complete:\n",
      "    Train loss: 3.782219629338514\n",
      "    Eval loss: 3.7824122938822375\n",
      "\n",
      "Learning rate: [7.730079211289578e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 350 complete:\n",
      "    Train loss: 3.782219628800583\n",
      "    Eval loss: 3.782412293891289\n",
      "\n",
      "Learning rate: [7.343575250725098e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 350\n",
      "\n",
      "Epoch 351 complete:\n",
      "    Train loss: 3.7822196282892526\n",
      "    Eval loss: 3.7824122939031937\n",
      "\n",
      "Learning rate: [6.976396488188844e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 352 complete:\n",
      "    Train loss: 3.7822196278037383\n",
      "    Eval loss: 3.782412293909024\n",
      "\n",
      "Learning rate: [6.627576663779401e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 353 complete:\n",
      "    Train loss: 3.7822196273428608\n",
      "    Eval loss: 3.782412293908613\n",
      "\n",
      "Learning rate: [6.296197830590431e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 354 complete:\n",
      "    Train loss: 3.7822196269057704\n",
      "    Eval loss: 3.7824122939023677\n",
      "\n",
      "Learning rate: [5.981387939060909e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 355 complete:\n",
      "    Train loss: 3.782219626489361\n",
      "    Eval loss: 3.78241229389434\n",
      "\n",
      "Learning rate: [5.6823185421078635e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 355\n",
      "\n",
      "Epoch 356 complete:\n",
      "    Train loss: 3.78221962609571\n",
      "    Eval loss: 3.782412293897849\n",
      "\n",
      "Learning rate: [5.3982026150024704e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 357 complete:\n",
      "    Train loss: 3.782219625720141\n",
      "    Eval loss: 3.7824122939038376\n",
      "\n",
      "Learning rate: [5.128292484252347e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 358 complete:\n",
      "    Train loss: 3.78221962536248\n",
      "    Eval loss: 3.7824122939008453\n",
      "\n",
      "Learning rate: [4.871877860039729e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 359 complete:\n",
      "    Train loss: 3.7822196250247724\n",
      "    Eval loss: 3.7824122939105616\n",
      "\n",
      "Learning rate: [4.6282839670377427e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 360 complete:\n",
      "    Train loss: 3.7822196247023196\n",
      "    Eval loss: 3.782412293922617\n",
      "\n",
      "Learning rate: [4.3968697686858555e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 360\n",
      "\n",
      "Epoch 361 complete:\n",
      "    Train loss: 3.7822196243967996\n",
      "    Eval loss: 3.7824122939415514\n",
      "\n",
      "Learning rate: [4.177026280251562e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 362 complete:\n",
      "    Train loss: 3.7822196241073702\n",
      "    Eval loss: 3.782412293955055\n",
      "\n",
      "Learning rate: [3.968174966238984e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 363 complete:\n",
      "    Train loss: 3.782219623831135\n",
      "    Eval loss: 3.7824122939653355\n",
      "\n",
      "Learning rate: [3.7697662179270344e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 364 complete:\n",
      "    Train loss: 3.782219623568999\n",
      "    Eval loss: 3.782412293974956\n",
      "\n",
      "Learning rate: [3.581277907030682e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 365 complete:\n",
      "    Train loss: 3.7822196233193193\n",
      "    Eval loss: 3.782412293980597\n",
      "\n",
      "Learning rate: [3.402214011679148e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 365\n",
      "\n",
      "Epoch 366 complete:\n",
      "    Train loss: 3.782219623082173\n",
      "    Eval loss: 3.782412293987679\n",
      "\n",
      "Learning rate: [3.23210331109519e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 367 complete:\n",
      "    Train loss: 3.782219622858136\n",
      "    Eval loss: 3.782412294000015\n",
      "\n",
      "Learning rate: [3.0704981455404306e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 368 complete:\n",
      "    Train loss: 3.7822196226439515\n",
      "    Eval loss: 3.7824122940077523\n",
      "\n",
      "Learning rate: [2.916973238263409e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 369 complete:\n",
      "    Train loss: 3.7822196224413736\n",
      "    Eval loss: 3.7824122940152693\n",
      "\n",
      "Learning rate: [2.7711245763502384e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 370 complete:\n",
      "    Train loss: 3.7822196222485114\n",
      "    Eval loss: 3.782412294021315\n",
      "\n",
      "Learning rate: [2.6325683475327264e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 370\n",
      "\n",
      "Epoch 371 complete:\n",
      "    Train loss: 3.782219622064937\n",
      "    Eval loss: 3.7824122940230915\n",
      "\n",
      "Learning rate: [2.50093993015609e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 372 complete:\n",
      "    Train loss: 3.7822196218914206\n",
      "    Eval loss: 3.7824122940278753\n",
      "\n",
      "Learning rate: [2.3758929336482854e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 373 complete:\n",
      "    Train loss: 3.7822196217263215\n",
      "    Eval loss: 3.7824122940315488\n",
      "\n",
      "Learning rate: [2.257098286965871e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 374 complete:\n",
      "    Train loss: 3.782219621568981\n",
      "    Eval loss: 3.782412294036011\n",
      "\n",
      "Learning rate: [2.1442433726175775e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 375 complete:\n",
      "    Train loss: 3.78221962142022\n",
      "    Eval loss: 3.782412294040735\n",
      "\n",
      "Learning rate: [2.0370312039866985e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 375\n",
      "\n",
      "Epoch 376 complete:\n",
      "    Train loss: 3.782219621278506\n",
      "    Eval loss: 3.7824122940455895\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 377 complete:\n",
      "    Train loss: 3.7822196211436765\n",
      "    Eval loss: 3.7824122940482554\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 378 complete:\n",
      "    Train loss: 3.782219621125584\n",
      "    Eval loss: 3.782412294051313\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 379 complete:\n",
      "    Train loss: 3.782219621107641\n",
      "    Eval loss: 3.782412294052839\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 380 complete:\n",
      "    Train loss: 3.7822196210896077\n",
      "    Eval loss: 3.7824122940555744\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 380\n",
      "\n",
      "Epoch 381 complete:\n",
      "    Train loss: 3.7822196210717642\n",
      "    Eval loss: 3.7824122940594402\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 382 complete:\n",
      "    Train loss: 3.7822196210538026\n",
      "    Eval loss: 3.7824122940612472\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 383 complete:\n",
      "    Train loss: 3.7822196210357273\n",
      "    Eval loss: 3.7824122940633034\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 384 complete:\n",
      "    Train loss: 3.782219621017827\n",
      "    Eval loss: 3.7824122940653675\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 385 complete:\n",
      "    Train loss: 3.7822196209998387\n",
      "    Eval loss: 3.7824122940672957\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 385\n",
      "\n",
      "Epoch 386 complete:\n",
      "    Train loss: 3.782219620981815\n",
      "    Eval loss: 3.7824122940689144\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 387 complete:\n",
      "    Train loss: 3.7822196209637893\n",
      "    Eval loss: 3.7824122940714213\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 388 complete:\n",
      "    Train loss: 3.7822196209457135\n",
      "    Eval loss: 3.782412294075185\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 389 complete:\n",
      "    Train loss: 3.7822196209277616\n",
      "    Eval loss: 3.7824122940787905\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 390 complete:\n",
      "    Train loss: 3.7822196209098786\n",
      "    Eval loss: 3.7824122940789953\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 390\n",
      "\n",
      "Epoch 391 complete:\n",
      "    Train loss: 3.78221962089208\n",
      "    Eval loss: 3.7824122940796867\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 392 complete:\n",
      "    Train loss: 3.7822196208742005\n",
      "    Eval loss: 3.7824122940824476\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 393 complete:\n",
      "    Train loss: 3.782219620856441\n",
      "    Eval loss: 3.7824122940821825\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 394 complete:\n",
      "    Train loss: 3.782219620838538\n",
      "    Eval loss: 3.782412294082316\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 395 complete:\n",
      "    Train loss: 3.7822196208208507\n",
      "    Eval loss: 3.7824122940825458\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 395\n",
      "\n",
      "Epoch 396 complete:\n",
      "    Train loss: 3.7822196208029504\n",
      "    Eval loss: 3.7824122940855687\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 397 complete:\n",
      "    Train loss: 3.7822196207850856\n",
      "    Eval loss: 3.782412294083982\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 398 complete:\n",
      "    Train loss: 3.782219620767144\n",
      "    Eval loss: 3.7824122940815164\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 399 complete:\n",
      "    Train loss: 3.7822196207492973\n",
      "    Eval loss: 3.782412294081726\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 400 complete:\n",
      "    Train loss: 3.7822196207315466\n",
      "    Eval loss: 3.7824122940821443\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 400\n",
      "\n",
      "Epoch 401 complete:\n",
      "    Train loss: 3.7822196207137315\n",
      "    Eval loss: 3.782412294079121\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 402 complete:\n",
      "    Train loss: 3.782219620695923\n",
      "    Eval loss: 3.7824122940789375\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 403 complete:\n",
      "    Train loss: 3.782219620677601\n",
      "    Eval loss: 3.782412294075942\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 404 complete:\n",
      "    Train loss: 3.78221962066017\n",
      "    Eval loss: 3.782412294072534\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 405 complete:\n",
      "    Train loss: 3.7822196206422385\n",
      "    Eval loss: 3.7824122940689686\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 405\n",
      "\n",
      "Epoch 406 complete:\n",
      "    Train loss: 3.782219620624715\n",
      "    Eval loss: 3.7824122940663427\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 407 complete:\n",
      "    Train loss: 3.7822196206065595\n",
      "    Eval loss: 3.782412294062692\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 408 complete:\n",
      "    Train loss: 3.78221962058901\n",
      "    Eval loss: 3.7824122940597067\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 409 complete:\n",
      "    Train loss: 3.782219620571689\n",
      "    Eval loss: 3.782412294058745\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 410 complete:\n",
      "    Train loss: 3.7822196205535836\n",
      "    Eval loss: 3.78241229405692\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 410\n",
      "\n",
      "Epoch 411 complete:\n",
      "    Train loss: 3.782219620536162\n",
      "    Eval loss: 3.782412294051913\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 412 complete:\n",
      "    Train loss: 3.782219620518117\n",
      "    Eval loss: 3.7824122940483744\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 413 complete:\n",
      "    Train loss: 3.7822196205008165\n",
      "    Eval loss: 3.7824122940467277\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 414 complete:\n",
      "    Train loss: 3.782219620482767\n",
      "    Eval loss: 3.7824122940445917\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 415 complete:\n",
      "    Train loss: 3.782219620465504\n",
      "    Eval loss: 3.782412294043359\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 415\n",
      "\n",
      "Epoch 416 complete:\n",
      "    Train loss: 3.7822196204474787\n",
      "    Eval loss: 3.782412294041262\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 417 complete:\n",
      "    Train loss: 3.7822196204300287\n",
      "    Eval loss: 3.782412294039439\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 418 complete:\n",
      "    Train loss: 3.782219620412346\n",
      "    Eval loss: 3.782412294038231\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 419 complete:\n",
      "    Train loss: 3.7822196203944065\n",
      "    Eval loss: 3.7824122940357703\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 420 complete:\n",
      "    Train loss: 3.782219620376992\n",
      "    Eval loss: 3.782412294035187\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 420\n",
      "\n",
      "Epoch 421 complete:\n",
      "    Train loss: 3.782219620359363\n",
      "    Eval loss: 3.7824122940350726\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 422 complete:\n",
      "    Train loss: 3.782219620341305\n",
      "    Eval loss: 3.782412294031294\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 423 complete:\n",
      "    Train loss: 3.782219620323934\n",
      "    Eval loss: 3.7824122940307587\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 424 complete:\n",
      "    Train loss: 3.7822196203064014\n",
      "    Eval loss: 3.7824122940290614\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 425 complete:\n",
      "    Train loss: 3.7822196202884917\n",
      "    Eval loss: 3.782412294026349\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 425\n",
      "\n",
      "Epoch 426 complete:\n",
      "    Train loss: 3.782219620271159\n",
      "    Eval loss: 3.782412294025819\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 427 complete:\n",
      "    Train loss: 3.782219620253652\n",
      "    Eval loss: 3.782412294023621\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 428 complete:\n",
      "    Train loss: 3.7822196202357143\n",
      "    Eval loss: 3.7824122940200233\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 429 complete:\n",
      "    Train loss: 3.782219620218415\n",
      "    Eval loss: 3.782412294017678\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 430 complete:\n",
      "    Train loss: 3.782219620200962\n",
      "    Eval loss: 3.7824122940142684\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 430\n",
      "\n",
      "Epoch 431 complete:\n",
      "    Train loss: 3.7822196201833065\n",
      "    Eval loss: 3.7824122940108555\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 432 complete:\n",
      "    Train loss: 3.7822196201655895\n",
      "    Eval loss: 3.782412294007254\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 433 complete:\n",
      "    Train loss: 3.7822196201476594\n",
      "    Eval loss: 3.78241229400214\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 434 complete:\n",
      "    Train loss: 3.782219620130486\n",
      "    Eval loss: 3.7824122939989246\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 435 complete:\n",
      "    Train loss: 3.782219620112472\n",
      "    Eval loss: 3.7824122939958946\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 435\n",
      "\n",
      "Epoch 436 complete:\n",
      "    Train loss: 3.7822196200945775\n",
      "    Eval loss: 3.7824122939939784\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 437 complete:\n",
      "    Train loss: 3.782219620076392\n",
      "    Eval loss: 3.782412293985402\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 438 complete:\n",
      "    Train loss: 3.782219620059117\n",
      "    Eval loss: 3.7824122939812694\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 439 complete:\n",
      "    Train loss: 3.782219620041206\n",
      "    Eval loss: 3.7824122939760714\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 440 complete:\n",
      "    Train loss: 3.78221962002393\n",
      "    Eval loss: 3.7824122939746774\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 440\n",
      "\n",
      "Epoch 441 complete:\n",
      "    Train loss: 3.782219620006166\n",
      "    Eval loss: 3.782412293971029\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 442 complete:\n",
      "    Train loss: 3.782219619989229\n",
      "    Eval loss: 3.7824122939714826\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 443 complete:\n",
      "    Train loss: 3.782219619971378\n",
      "    Eval loss: 3.7824122939705935\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 444 complete:\n",
      "    Train loss: 3.782219619953969\n",
      "    Eval loss: 3.7824122939684677\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 445 complete:\n",
      "    Train loss: 3.782219619936172\n",
      "    Eval loss: 3.782412293968728\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 445\n",
      "\n",
      "Epoch 446 complete:\n",
      "    Train loss: 3.7822196199190334\n",
      "    Eval loss: 3.7824122939652915\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 447 complete:\n",
      "    Train loss: 3.7822196199012126\n",
      "    Eval loss: 3.782412293960805\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 448 complete:\n",
      "    Train loss: 3.782219619884128\n",
      "    Eval loss: 3.7824122939607654\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 449 complete:\n",
      "    Train loss: 3.782219619866649\n",
      "    Eval loss: 3.782412293958504\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 450 complete:\n",
      "    Train loss: 3.7822196198489304\n",
      "    Eval loss: 3.782412293953766\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 450\n",
      "\n",
      "Epoch 451 complete:\n",
      "    Train loss: 3.782219619831747\n",
      "    Eval loss: 3.7824122939533265\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 452 complete:\n",
      "    Train loss: 3.7822196198143345\n",
      "    Eval loss: 3.7824122939494855\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 453 complete:\n",
      "    Train loss: 3.7822196197967055\n",
      "    Eval loss: 3.782412293944079\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 454 complete:\n",
      "    Train loss: 3.782219619779522\n",
      "    Eval loss: 3.7824122939437586\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 455 complete:\n",
      "    Train loss: 3.782219619761594\n",
      "    Eval loss: 3.782412293939556\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 455\n",
      "\n",
      "Epoch 456 complete:\n",
      "    Train loss: 3.782219619744256\n",
      "    Eval loss: 3.7824122939384583\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 457 complete:\n",
      "    Train loss: 3.7822196197263795\n",
      "    Eval loss: 3.7824122939343545\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 458 complete:\n",
      "    Train loss: 3.782219619709083\n",
      "    Eval loss: 3.7824122939309492\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 459 complete:\n",
      "    Train loss: 3.7822196196913183\n",
      "    Eval loss: 3.7824122939231817\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 460 complete:\n",
      "    Train loss: 3.782219619674096\n",
      "    Eval loss: 3.7824122939205953\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 460\n",
      "\n",
      "Epoch 461 complete:\n",
      "    Train loss: 3.782219619656153\n",
      "    Eval loss: 3.7824122939144167\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 462 complete:\n",
      "    Train loss: 3.7822196196386826\n",
      "    Eval loss: 3.782412293907644\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 463 complete:\n",
      "    Train loss: 3.7822196196215043\n",
      "    Eval loss: 3.7824122939013862\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 464 complete:\n",
      "    Train loss: 3.7822196196033224\n",
      "    Eval loss: 3.782412293894008\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 465 complete:\n",
      "    Train loss: 3.7822196195863795\n",
      "    Eval loss: 3.782412293887003\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 465\n",
      "\n",
      "Epoch 466 complete:\n",
      "    Train loss: 3.782219619568476\n",
      "    Eval loss: 3.782412293879628\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 467 complete:\n",
      "    Train loss: 3.782219619550926\n",
      "    Eval loss: 3.7824122938740237\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 468 complete:\n",
      "    Train loss: 3.7822196195336613\n",
      "    Eval loss: 3.7824122938663804\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 469 complete:\n",
      "    Train loss: 3.782219619515861\n",
      "    Eval loss: 3.7824122938597537\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 470 complete:\n",
      "    Train loss: 3.782219619498628\n",
      "    Eval loss: 3.7824122938557148\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 470\n",
      "\n",
      "Epoch 471 complete:\n",
      "    Train loss: 3.7822196194814226\n",
      "    Eval loss: 3.782412293846607\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 472 complete:\n",
      "    Train loss: 3.782219619464195\n",
      "    Eval loss: 3.7824122938402196\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 473 complete:\n",
      "    Train loss: 3.7822196194461446\n",
      "    Eval loss: 3.7824122938333327\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 474 complete:\n",
      "    Train loss: 3.7822196194286506\n",
      "    Eval loss: 3.7824122938273663\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 475 complete:\n",
      "    Train loss: 3.7822196194112534\n",
      "    Eval loss: 3.782412293824008\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 475\n",
      "\n",
      "Epoch 476 complete:\n",
      "    Train loss: 3.7822196193935214\n",
      "    Eval loss: 3.782412293819013\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 477 complete:\n",
      "    Train loss: 3.7822196193759163\n",
      "    Eval loss: 3.782412293813771\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 478 complete:\n",
      "    Train loss: 3.782219619358666\n",
      "    Eval loss: 3.7824122938094824\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 479 complete:\n",
      "    Train loss: 3.782219619340635\n",
      "    Eval loss: 3.782412293802808\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 480 complete:\n",
      "    Train loss: 3.782219619322955\n",
      "    Eval loss: 3.782412293796157\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 480\n",
      "\n",
      "Epoch 481 complete:\n",
      "    Train loss: 3.7822196193056437\n",
      "    Eval loss: 3.7824122937911464\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 482 complete:\n",
      "    Train loss: 3.7822196192877295\n",
      "    Eval loss: 3.782412293785506\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 483 complete:\n",
      "    Train loss: 3.782219619270465\n",
      "    Eval loss: 3.782412293781832\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 484 complete:\n",
      "    Train loss: 3.7822196192525577\n",
      "    Eval loss: 3.782412293776356\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 485 complete:\n",
      "    Train loss: 3.7822196192349486\n",
      "    Eval loss: 3.7824122937723743\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 485\n",
      "\n",
      "Epoch 486 complete:\n",
      "    Train loss: 3.7822196192177553\n",
      "    Eval loss: 3.7824122937675524\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 487 complete:\n",
      "    Train loss: 3.7822196191996302\n",
      "    Eval loss: 3.7824122937644993\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 488 complete:\n",
      "    Train loss: 3.782219619181803\n",
      "    Eval loss: 3.7824122937599025\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 489 complete:\n",
      "    Train loss: 3.7822196191645663\n",
      "    Eval loss: 3.782412293756742\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 490 complete:\n",
      "    Train loss: 3.7822196191465167\n",
      "    Eval loss: 3.782412293752344\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 490\n",
      "\n",
      "Epoch 491 complete:\n",
      "    Train loss: 3.7822196191287554\n",
      "    Eval loss: 3.782412293747317\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 492 complete:\n",
      "    Train loss: 3.7822196191114084\n",
      "    Eval loss: 3.782412293745141\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 493 complete:\n",
      "    Train loss: 3.7822196190935533\n",
      "    Eval loss: 3.782412293738538\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 494 complete:\n",
      "    Train loss: 3.7822196190759163\n",
      "    Eval loss: 3.7824122937347147\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 495 complete:\n",
      "    Train loss: 3.782219619058475\n",
      "    Eval loss: 3.782412293730178\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved checkpoint at epoch: 495\n",
      "\n",
      "Epoch 496 complete:\n",
      "    Train loss: 3.782219619040623\n",
      "    Eval loss: 3.7824122937234974\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 497 complete:\n",
      "    Train loss: 3.782219619023606\n",
      "    Eval loss: 3.7824122937212565\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 498 complete:\n",
      "    Train loss: 3.782219619005799\n",
      "    Eval loss: 3.782412293719378\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "\n",
      "Epoch 499 complete:\n",
      "    Train loss: 3.782219618988624\n",
      "    Eval loss: 3.782412293713404\n",
      "\n",
      "Learning rate: [1.9351796437873634e-08]\n",
      "Peak GPU memory usage:\n",
      "0.03575 GB\n",
      "Saved loss table.\n",
      "Saved final at epoch: 499\n",
      "Unloaded dataset.\n",
      "Unloaded dataset.\n"
     ]
    }
   ],
   "source": [
    "for level in (Names_Levels().detector_and_background,):\n",
    "\n",
    "    experiment.train(\n",
    "        config_model=config_experiment_ebe.get_config_model(\n",
    "            level=level, \n",
    "        ),\n",
    "        config_dset_eval=config_experiment_ebe.get_config_dset(\n",
    "            level=level, \n",
    "            split=Names_Splits().eval_,\n",
    "        ),\n",
    "        generate_dsets=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ffb3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.plot.loss_curves import plot_loss_curves\n",
    "\n",
    "plot_loss_curves(\n",
    "    config_model=config_experiment_ebe.get_config_model(\n",
    "        level=Names_Levels().detector_and_background, \n",
    "    ),\n",
    "    config_dset_eval=config_experiment_ebe.get_config_dset(\n",
    "        level=Names_Levels().detector_and_background, \n",
    "        split=Names_Splits().eval_,\n",
    "    ),\n",
    "    path_dir=path_dir_plots,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebfd319",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b164fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\70000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tetha\\Desktop\\btokstll\\logic\\scripts\\helpers\\result\\table.py:37: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  self.table.loc[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tensor of shape: torch.Size([2000, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\24000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2000, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_gen_q2v_loose\\6000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2000, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 70000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\70000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2000, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 24000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\24000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2000, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_sens_features.pt\n",
      "Loaded tensor of shape: torch.Size([2000, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_sens_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_sens_bin_map.pt\n",
      "Loaded dataset: sets_binned\n",
      "Loaded tensor of shape: torch.Size([2200, 6000, 4]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_features.pt\n",
      "Loaded tensor of shape: torch.Size([2200, 44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_labels.pt\n",
      "Loaded tensor of shape: torch.Size([44]) from: ..\\..\\state\\new_physics\\data\\processed\\sets_binned_det_q2v_loose\\6000_eval_bin_map.pt\n",
      "Loaded dataset: sets_binned\n"
     ]
    }
   ],
   "source": [
    "for level in (Names_Levels().generator, Names_Levels().detector):\n",
    "\n",
    "    for num_events_per_set in Nums_Events_Per_Set().tuple_:\n",
    "\n",
    "        experiment.evaluate(\n",
    "            config_model=config_experiment_ebe.get_config_model(\n",
    "                level=level, \n",
    "            ), \n",
    "            config_dset_eval=config_experiment_ebe.get_config_dset(\n",
    "                level=level, \n",
    "                split=Names_Splits().eval_,\n",
    "                num_events_per_set=num_events_per_set, \n",
    "            ),\n",
    "            config_dset_eval_sens=config_experiment_ebe.get_config_dset(\n",
    "                level=level, \n",
    "                split=Names_Splits().eval_,\n",
    "                sens=True,\n",
    "                num_events_per_set=num_events_per_set, \n",
    "            ),\n",
    "            generate_dsets=False, \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076dd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.table_summary.table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5c660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "split = \"train\"\n",
    "\n",
    "bounds_trials = (\n",
    "    (1, 20) if split == \"eval\" \n",
    "    else (21, 40) if split == \"train\" \n",
    "    else None\n",
    ")\n",
    "\n",
    "df = pandas.concat(\n",
    "    [\n",
    "        pandas.read_pickle(f\"../../state/new_physics/data/processed/agg_sig_{bounds_trials[0]}_to_{bounds_trials[1]}_det.pkl\"),\n",
    "        pandas.read_pickle(f\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_{split}_scaled.pkl\"),\n",
    "        pandas.read_pickle(f\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_{split}_scaled.pkl\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df[(df[\"q_squared\"] < 20) & (df[\"q_squared\"] > 0)].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ceece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcdaf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tetha\\AppData\\Local\\Temp\\ipykernel_8836\\2133017417.py:57: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  y = table.loc[\n",
      "C:\\Users\\tetha\\AppData\\Local\\Temp\\ipykernel_8836\\2133017417.py:86: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  table.loc[\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "from helpers.plot.util import add_plot_note\n",
    "from helpers.result.constants import Names_Kinds_Items\n",
    "\n",
    "\n",
    "def plot(table):\n",
    "\n",
    "    y_lims = [\n",
    "        (0, 0.58), \n",
    "        (0, 0.62), \n",
    "        (0, 0.65), \n",
    "        (-1.2, -0.65), \n",
    "        (-0.4, 0.4)\n",
    "    ]\n",
    "\n",
    "    num_sets_nominal = 50\n",
    "    num_sets_sens = 2000\n",
    "\n",
    "    q_squared_veto = Names_q_Squared_Vetos().loose\n",
    "\n",
    "    names_models = (Names_Models().cnn, Names_Models().deep_sets, Names_Models().ebe)\n",
    "\n",
    "    markers = [\"o\", \"v\", \"s\"]\n",
    "    colors = [\"#999999\", \"#377eb8\", \"#a65628\"]\n",
    "\n",
    "    linestyles = [\"-\", \"--\", \"-.\"]\n",
    "\n",
    "    for col, y_lim in zip(\n",
    "        table.columns, \n",
    "        y_lims\n",
    "    ):\n",
    "\n",
    "        _, ax = plt.subplots()\n",
    "        \n",
    "        for name_model, marker, color in zip(\n",
    "            names_models, \n",
    "            markers, \n",
    "            colors\n",
    "        ):\n",
    "            \n",
    "            for level, linestyle in zip(\n",
    "                Names_Levels().tuple_, \n",
    "                linestyles\n",
    "            ):\n",
    "                \n",
    "                if (\n",
    "                    (name_model == Names_Models().ebe) \n",
    "                    and (level == Names_Levels().detector_and_background)\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                y = table.loc[\n",
    "                    pandas.IndexSlice[\n",
    "                        level, \n",
    "                        q_squared_veto, \n",
    "                        name_model,\n",
    "                    ], \n",
    "                    col,\n",
    "                ]\n",
    "\n",
    "                x = y.index\n",
    "\n",
    "                fmt = linestyle + marker\n",
    "                \n",
    "                ax.plot(\n",
    "                    x, \n",
    "                    y, \n",
    "                    fmt, \n",
    "                    label=f\"{name_model}, {level}\", \n",
    "                    c=color, \n",
    "                    markersize=5, \n",
    "                    alpha=.8\n",
    "                    )\n",
    "                \n",
    "                if (\n",
    "                    (col==Names_Kinds_Items().np_bias) \n",
    "                    or (col==Names_Kinds_Items().np_mean)\n",
    "                ):\n",
    "                \n",
    "                    errors = (\n",
    "                        table.loc[\n",
    "                            pandas.IndexSlice[\n",
    "                                level, \n",
    "                                q_squared_veto, \n",
    "                                name_model,\n",
    "                            ], \n",
    "                            Names_Kinds_Items().np_std,\n",
    "                        ] \n",
    "                        / sqrt(num_sets_sens)\n",
    "                    )\n",
    "                \n",
    "                    ax.errorbar(\n",
    "                        x=x, \n",
    "                        y=y, \n",
    "                        yerr=errors, \n",
    "                        fmt='none', \n",
    "                        elinewidth=0.5, \n",
    "                        capsize=0.5, \n",
    "                        color=\"black\",\n",
    "                    )\n",
    "\n",
    "            ax.set_ylim(y_lim)\n",
    "            ax.set_ylabel(f\"{col}\")\n",
    "            ax.set_xlabel(\"Number of events / set\")\n",
    "            ax.legend(ncols=2, markerscale=0.5, numpoints=1)\n",
    "\n",
    "            if (\n",
    "                (col==Names_Kinds_Items().np_bias) \n",
    "                or (col==Names_Kinds_Items().np_mean) \n",
    "                or (col==Names_Kinds_Items().np_std)\n",
    "            ):\n",
    "                add_plot_note(\n",
    "                    ax, \n",
    "                    f\"Num boots.: {num_sets_sens}\",\n",
    "                )\n",
    "            \n",
    "            else: \n",
    "                add_plot_note(\n",
    "                    ax, \n",
    "                    f\"Num boots./label: {num_sets_nominal}\",\n",
    "                )\n",
    "\n",
    "        file_name = f\"comp_{col}.png\"\n",
    "        file_path = pathlib.Path(path_dir_plots).joinpath(file_name)\n",
    "\n",
    "        plt.savefig(file_path, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "plot(experiment.table_summary.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73174b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa3b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df_charge = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_whole.pkl\")\n",
    "\n",
    "df_mix = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_whole.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abfdfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    ind_half = int(len(df)/2)\n",
    "    df_train = df[:ind_half].copy()\n",
    "    df_eval = df[ind_half:].copy()\n",
    "    return df_train, df_eval\n",
    "\n",
    "df_charge_train, df_charge_eval = split(df_charge.loc[\"det\"][list(Names_Variables().tuple_)])\n",
    "\n",
    "df_mix_train, df_mix_eval = split(df_mix.loc[\"det\"][list(Names_Variables().tuple_)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc433c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_pickle(df_charge_train, \"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_pickle(df_charge_eval, \"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_eval.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ea0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_pickle(df_mix_train, \"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_train.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46475fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.to_pickle(df_mix_eval, \"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_eval.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e61205",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ee2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_eval.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7aac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b390b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_eval.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7092f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from helpers.data.dset.preproc import apply_q_squared_veto\n",
    "\n",
    "\n",
    "df_bkg_charge = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_charge_train.pkl\")\n",
    "df_bkg_mix = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_train.pkl\")\n",
    "\n",
    "df_bkg = pandas.concat([df_bkg_charge, df_bkg_mix])\n",
    "\n",
    "df_agg = pandas.read_pickle(\"../../state/new_physics/data/processed/agg_sig_1_to_20_det.pkl\")\n",
    "\n",
    "df_combo = pandas.concat([df_bkg[list(Names_Variables().tuple_)], df_agg[list(Names_Variables().tuple_)]])\n",
    "\n",
    "df_combo_q2v_tight = apply_q_squared_veto(df_combo, \"tight\")\n",
    "\n",
    "df_combo_q2v_tight.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaae35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_pickle(\"../../state/new_physics/data/raw/bkg/mu_sideb_generic_mix_whole.pkl\").loc[\"det\"]\n",
    "df[df[\"isSignal\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93beb219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2807b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
