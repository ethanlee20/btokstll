{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing what Shawn did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "\n",
    "from library.datasets import Signal_Images_Dataset\n",
    "from library.nn_training import select_device, train_and_eval, Custom_Model\n",
    "from library.plotting import plot_loss_curves, setup_high_quality_mpl_params, plot_prediction_linearity\n",
    "\n",
    "# setup_high_quality_mpl_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = select_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected argument value expression (3659986742.py, line 47)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[25], line 47\u001b[1;36m\u001b[0m\n\u001b[1;33m    nn.MaxPool3d(kernel_size=3, stride=2, padding=),\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expected argument value expression\n"
     ]
    }
   ],
   "source": [
    "class Res_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm3d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            nn.BatchNorm3d(num_features=out_channels),\n",
    "        )\n",
    "        self.last_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.block(x) + x\n",
    "        x = self.last_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block_a = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=\"same\"),\n",
    "            nn.BatchNorm3d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=\"same\"),\n",
    "            nn.BatchNorm3d(num_features=out_channels),\n",
    "        )\n",
    "        self.block_b = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=2, padding=\"same\"),\n",
    "            nn.BatchNorm3d(num_features=out_channels),\n",
    "        )\n",
    "        self.last_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.block_a(x) + self.block_b(x)\n",
    "        x = self.last_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_Res(Custom_Model):\n",
    "    def __init__(self, nickname, model_dir, in_channels):\n",
    "        super().__init__(nickname, model_dir)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=64, kernel_size=7, stride=2, padding=\"same\", bias=False),\n",
    "            nn.BatchNorm3d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=3, stride=2, padding=\"same\"),\n",
    "            Res_Block(in_channels=???, out_channels=64),\n",
    "            *[Res_Block(in_channels=64, out_channels=64) for _ in range(2)],\n",
    "            Conv_Block(in_channels=64, out_channels=128),\n",
    "            *[Res_Block(in_channels=128, out_channels=128) for _ in range(3)],\n",
    "            Conv_Block(in_channels=128, out_channels=256),\n",
    "            *[Res_Block(in_channels=256, out_channels=256) for _ in range(4)],\n",
    "            Conv_Block(in_channels=256, out_channels=512),\n",
    "            *[Res_Block(in_channels=512, out_channels=512) for _ in range(2)],\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=1000),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=1000, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=(???))\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.dense(x) # squeeze?\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Signal_Images_Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 17\u001b[0m\n\u001b[0;32m      4\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../state/new_physics/data/processed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m common_generate_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_signal_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../state/new_physics/data/raw/signal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_bins\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     14\u001b[0m }\n\u001b[0;32m     16\u001b[0m datasets \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mSignal_Images_Dataset\u001b[49m(level\u001b[38;5;241m=\u001b[39mlevel, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39msave_dir),\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m: Signal_Images_Dataset(level\u001b[38;5;241m=\u001b[39mlevel, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, save_dir\u001b[38;5;241m=\u001b[39msave_dir),\n\u001b[0;32m     19\u001b[0m }\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m regenerate:\n\u001b[0;32m     22\u001b[0m     datasets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     23\u001b[0m         raw_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m), \n\u001b[0;32m     24\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcommon_generate_kwargs\n\u001b[0;32m     25\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Signal_Images_Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "regenerate = True\n",
    "\n",
    "level = \"gen\"\n",
    "save_dir = \"../../state/new_physics/data/processed\"\n",
    "\n",
    "common_generate_kwargs = {\n",
    "    \"raw_signal_dir\": \"../../state/new_physics/data/raw/signal\",\n",
    "    \"std_scale\": True,\n",
    "    \"q_squared_veto\": True,\n",
    "    \"balanced_classes\": True,\n",
    "    \"num_events_per_set\": 24_000,\n",
    "    \"num_sets_per_label\": 30,\n",
    "    \"n_bins\": 10,\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    \"train\": Signal_Images_Dataset(level=level, split=\"train\", save_dir=save_dir),\n",
    "    \"eval\": Signal_Images_Dataset(level=level, split=\"eval\", save_dir=save_dir),\n",
    "}\n",
    "\n",
    "if regenerate:\n",
    "    datasets[\"train\"].generate(\n",
    "        raw_trials=range(1,5), \n",
    "        **common_generate_kwargs\n",
    "    )\n",
    "    datasets[\"eval\"].generate(\n",
    "        raw_trials=range(5,10), \n",
    "        **common_generate_kwargs\n",
    "    )\n",
    "\n",
    "datasets[\"train\"].load(device)\n",
    "datasets[\"eval\"].load(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volume_slices(arr, n_slices=3, cmap=plt.cm.magma, note=\"\"):\n",
    "    \"\"\"\n",
    "    Plot slices of volumetric data.\n",
    "    Slices are along the z-axis (axis 2).\n",
    "    Array arr should be a three-dimensional array.\n",
    "    Slices might not be evenly spaced along z-axis.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax_3d = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    var_dim = {\n",
    "        0: \"chi\",\n",
    "        1: \"costheta_mu\",\n",
    "        2: \"costheta_K\",\n",
    "    }\n",
    "\n",
    "    dim_ind_cart = { # dont change for now\n",
    "        \"x\": 1,     \n",
    "        \"y\": 2,\n",
    "        \"z\": 0,  \n",
    "    }\n",
    "\n",
    "    norm=Normalize(vmin=-1.1, vmax=1.1)\n",
    "    arr = arr.cpu()\n",
    "    arr = np.transpose(\n",
    "        arr, \n",
    "        (dim_ind_cart[\"x\"], dim_ind_cart[\"y\"], dim_ind_cart[\"z\"])\n",
    "    )\n",
    "    colors = cmap(norm(arr))\n",
    "    \n",
    "    cart_dim_shape = {\n",
    "        dim_name: arr.shape[dim_ind_cart[dim_name]] for dim_name in dim_ind_cart.keys()\n",
    "    }\n",
    "\n",
    "    def xy_plane(z_pos):\n",
    "        x, y = np.indices(\n",
    "            (cart_dim_shape[\"x\"] + 1, cart_dim_shape[\"y\"] + 1)\n",
    "        )\n",
    "        z = np.full(\n",
    "            (cart_dim_shape[\"x\"] + 1, cart_dim_shape[\"y\"] + 1), z_pos\n",
    "        )\n",
    "        return x, y, z\n",
    "    \n",
    "    def plot_slice(z_index):\n",
    "        x, y, z = xy_plane(z_index) \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            facecolors=colors[:,:,z_index], \n",
    "            shade=False,\n",
    "        )\n",
    "\n",
    "    def plot_outline(z_index, offset=0.3):\n",
    "        x, y, z = xy_plane(z_index - offset)\n",
    "        \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            shade=False,\n",
    "            color=\"#f2f2f2\",\n",
    "            edgecolor=\"#f2f2f2\", \n",
    "        )\n",
    "\n",
    "    z_indices = np.linspace(0, cart_dim_shape[\"z\"]-1, n_slices, dtype=int) # forces integer indices\n",
    "    for i in z_indices:\n",
    "        plot_outline(i)\n",
    "        plot_slice(i)\n",
    "\n",
    "    cbar = fig.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=ax_3d, location=\"left\", shrink=0.5, pad=-0.05)\n",
    "    cbar.set_label(r\"${q^2}$ (Avg.)\", size=11)\n",
    "\n",
    "    ax_labels = {\n",
    "        \"chi\": r\"$\\chi$\", \n",
    "        \"costheta_mu\": r\"$\\cos\\theta_\\mu$\",\n",
    "        \"costheta_K\": r\"$\\cos\\theta_K$\",\n",
    "    }\n",
    "\n",
    "    ax_3d.set_xlabel(ax_labels[var_dim[dim_ind_cart[\"x\"]]], labelpad=0)\n",
    "    ax_3d.set_ylabel(ax_labels[var_dim[dim_ind_cart[\"y\"]]], labelpad=0)\n",
    "    # ax_3d.zaxis.set_rotate_label(False)\n",
    "    ax_3d.set_zlabel(ax_labels[var_dim[dim_ind_cart[\"z\"]]], labelpad=-3,)#rotation=\"horizontal\") \n",
    "\n",
    "    ticks = {\n",
    "        \"costheta_mu\": [\"-1\", \"1\"],\n",
    "        \"costheta_K\": [\"-1\", \"1\"],\n",
    "        \"chi\": ['0', r\"$2\\pi$\"],\n",
    "    }      \n",
    "\n",
    "    ax_3d.set_xticks([0, arr.shape[dim_ind_cart[\"x\"]]-1], ticks[var_dim[dim_ind_cart[\"x\"]]])\n",
    "    ax_3d.set_yticks([0, arr.shape[dim_ind_cart[\"y\"]]-1], ticks[var_dim[dim_ind_cart[\"y\"]]])\n",
    "    ax_3d.set_zticks([0, arr.shape[dim_ind_cart[\"z\"]]-1], ticks[var_dim[dim_ind_cart[\"z\"]]])\n",
    "\n",
    "    ax_3d.tick_params(pad=0.3)\n",
    "\n",
    "    ax_3d.set_box_aspect(None, zoom=0.85)\n",
    "\n",
    "    ax_3d.set_title(f\"{note}\", loc=\"center\", y=1)\n",
    "\n",
    "    # make_plot_note(ax_3d, f\"{note}\", fontsize=\"large\")\n",
    "\n",
    "    # plt.show()\n",
    "\n",
    "for i, (arr, label) in enumerate(zip(datasets[\"train\"].features, datasets[\"train\"].labels)):\n",
    "    n_slices = 3\n",
    "    if i%30==0:\n",
    "        plot_volume_slices(arr, n_slices=n_slices, note=r\"$\\delta C_9$ : \"+f\"{label}\")\n",
    "        plt.savefig(f\"{i}\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "\n",
    "model = CNN(\"cnn_with_checkpoints\", \"../../state/new_physics/models\")\n",
    "\n",
    "if retrain:\n",
    "    learning_rate = 3e-4\n",
    "    epochs = 20\n",
    "    train_batch_size = 32\n",
    "    eval_batch_size = 32\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_and_eval(\n",
    "        model, \n",
    "        datasets[\"train\"], datasets[\"eval\"], \n",
    "        loss_fn, optimizer, \n",
    "        epochs, \n",
    "        train_batch_size, eval_batch_size, \n",
    "        device, \n",
    "        move_data=False,\n",
    "        scheduler=None,\n",
    "        checkpoint_epochs=5,\n",
    "    )\n",
    "    _, ax = plt.subplots()\n",
    "    plot_epoch_start = 0\n",
    "    plot_loss_curves(\n",
    "        model.loss_table[\"epoch\"][plot_epoch_start:], \n",
    "        model.loss_table[\"train_loss\"][plot_epoch_start:], \n",
    "        model.loss_table[\"eval_loss\"][plot_epoch_start:], \n",
    "        ax\n",
    "    )\n",
    "    # ax.set_yscale(\"log\")\n",
    "    plt.show()\n",
    "else:\n",
    "    model.load_final()\n",
    "    # model.load_checkpoint(epoch_number=10)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(datasets[\"eval\"].features)\n",
    "avgs = yhat.reshape(-1, 30).mean(1).detach().cpu().numpy()\n",
    "stds = yhat.reshape(-1, 30).std(1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = datasets[\"eval\"].labels\n",
    "unique_y = y.reshape(-1, 30).mean(1).detach().cpu().numpy()\n",
    "unique_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_prediction_linearity(ax, unique_y, avgs, stds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maybe_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
