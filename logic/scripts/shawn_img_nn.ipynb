{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing what Shawn did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "\n",
    "from library.datasets import Signal_Images_Dataset\n",
    "from library.nn_training import select_device, train_and_eval, Custom_Model\n",
    "from library.plotting import plot_loss_curves, setup_high_quality_mpl_params, plot_prediction_linearity, make_plot_note\n",
    "\n",
    "device = select_device()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_Block(nn.Module):\n",
    "    def __init__(self, in_out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_out_channels, out_channels=in_out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            # nn.BatchNorm3d(num_features=in_out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=in_out_channels, out_channels=in_out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            # nn.BatchNorm3d(num_features=in_out_channels),\n",
    "        )\n",
    "        self.last_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.block(x) + x\n",
    "        x = self.last_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv_Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block_a = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            # nn.BatchNorm3d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            # nn.BatchNorm3d(num_features=out_channels),\n",
    "        )\n",
    "        self.block_b = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=\"same\"),\n",
    "            # nn.BatchNorm3d(num_features=out_channels),\n",
    "        )\n",
    "        self.last_activation = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        out_block_a = self.block_a(x)\n",
    "        out_block_b = self.block_b(x)\n",
    "        x = out_block_a + out_block_b\n",
    "        x = self.last_activation(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN_Res(Custom_Model):\n",
    "    def __init__(self, nickname, model_dir,):\n",
    "        super().__init__(nickname, model_dir)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=\"same\", bias=False),\n",
    "            # nn.BatchNorm3d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=2, stride=1, padding=1),\n",
    "            *[Res_Block(in_out_channels=16) for _ in range(3)],\n",
    "            Conv_Block(in_channels=16, out_channels=16),\n",
    "            *[Res_Block(in_out_channels=16) for _ in range(3)],\n",
    "            Conv_Block(in_channels=16, out_channels=16),\n",
    "            *[Res_Block(in_out_channels=16) for _ in range(3)],\n",
    "            # Conv_Block(in_channels=128, out_channels=128),\n",
    "            # *[Res_Block(in_out_channels=128) for _ in range(1)],\n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_features=16, out_features=32),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "        \n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = torch.mean(x, dim=(2,3,4))\n",
    "        x = self.dense(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate = True\n",
    "\n",
    "level = \"gen\"\n",
    "save_dir = \"../../state/new_physics/data/processed\"\n",
    "\n",
    "common_generate_kwargs = {\n",
    "    \"raw_signal_dir\": \"../../state/new_physics/data/raw/signal\",\n",
    "    \"std_scale\": True,\n",
    "    \"q_squared_veto\": True,\n",
    "    \"balanced_classes\": True,\n",
    "    \"num_events_per_set\": 70_000,\n",
    "    \"num_sets_per_label\": 50,\n",
    "    \"n_bins\": 10,\n",
    "}\n",
    "\n",
    "datasets = {\n",
    "    \"train\": Signal_Images_Dataset(level=level, split=\"train\", save_dir=save_dir),\n",
    "    \"eval\": Signal_Images_Dataset(level=level, split=\"eval\", save_dir=save_dir),\n",
    "}\n",
    "\n",
    "if regenerate:\n",
    "    datasets[\"train\"].generate(\n",
    "        raw_trials=range(1,21), \n",
    "        **common_generate_kwargs\n",
    "    )\n",
    "    datasets[\"eval\"].generate(\n",
    "        raw_trials=range(21,41), \n",
    "        **common_generate_kwargs\n",
    "    )\n",
    "\n",
    "datasets[\"train\"].load(device)\n",
    "datasets[\"eval\"].load(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_volume_slices(arr, n_slices=3, cmap=plt.cm.magma, note=\"\"):\n",
    "    \"\"\"\n",
    "    Plot slices of volumetric data.\n",
    "    Slices are along the z-axis (axis 2).\n",
    "    Array arr should be a three-dimensional array.\n",
    "    Slices might not be evenly spaced along z-axis.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax_3d = fig.add_subplot(projection=\"3d\")\n",
    "\n",
    "    var_dim = {\n",
    "        0: \"chi\",\n",
    "        1: \"costheta_mu\",\n",
    "        2: \"costheta_K\",\n",
    "    }\n",
    "\n",
    "    dim_ind_cart = { # dont change for now\n",
    "        \"x\": 1,     \n",
    "        \"y\": 2,\n",
    "        \"z\": 0,  \n",
    "    }\n",
    "\n",
    "    norm=Normalize(vmin=-1.1, vmax=1.1)\n",
    "    arr = arr.squeeze()\n",
    "    arr = arr.cpu()\n",
    "    arr = np.transpose(\n",
    "        arr, \n",
    "        (dim_ind_cart[\"x\"], dim_ind_cart[\"y\"], dim_ind_cart[\"z\"])\n",
    "    )\n",
    "    colors = cmap(norm(arr))\n",
    "    \n",
    "    cart_dim_shape = {\n",
    "        dim_name: arr.shape[dim_ind_cart[dim_name]] for dim_name in dim_ind_cart.keys()\n",
    "    }\n",
    "\n",
    "    def xy_plane(z_pos):\n",
    "        x, y = np.indices(\n",
    "            (cart_dim_shape[\"x\"] + 1, cart_dim_shape[\"y\"] + 1)\n",
    "        )\n",
    "        z = np.full(\n",
    "            (cart_dim_shape[\"x\"] + 1, cart_dim_shape[\"y\"] + 1), z_pos\n",
    "        )\n",
    "        return x, y, z\n",
    "    \n",
    "    def plot_slice(z_index):\n",
    "        x, y, z = xy_plane(z_index) \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            facecolors=colors[:,:,z_index], \n",
    "            shade=False,\n",
    "        )\n",
    "\n",
    "    def plot_outline(z_index, offset=0.3):\n",
    "        x, y, z = xy_plane(z_index - offset)\n",
    "        \n",
    "        ax_3d.plot_surface(\n",
    "            x, y, z, \n",
    "            rstride=1, cstride=1, \n",
    "            shade=False,\n",
    "            color=\"#f2f2f2\",\n",
    "            edgecolor=\"#f2f2f2\", \n",
    "        )\n",
    "\n",
    "    z_indices = np.linspace(0, cart_dim_shape[\"z\"]-1, n_slices, dtype=int) # forces integer indices\n",
    "    for i in z_indices:\n",
    "        plot_outline(i)\n",
    "        plot_slice(i)\n",
    "\n",
    "    cbar = fig.colorbar(ScalarMappable(norm=norm, cmap=cmap), ax=ax_3d, location=\"left\", shrink=0.5, pad=-0.05)\n",
    "    cbar.set_label(r\"${q^2}$ (Avg.)\", size=11)\n",
    "\n",
    "    ax_labels = {\n",
    "        \"chi\": r\"$\\chi$\", \n",
    "        \"costheta_mu\": r\"$\\cos\\theta_\\mu$\",\n",
    "        \"costheta_K\": r\"$\\cos\\theta_K$\",\n",
    "    }\n",
    "\n",
    "    ax_3d.set_xlabel(ax_labels[var_dim[dim_ind_cart[\"x\"]]], labelpad=0)\n",
    "    ax_3d.set_ylabel(ax_labels[var_dim[dim_ind_cart[\"y\"]]], labelpad=0)\n",
    "    # ax_3d.zaxis.set_rotate_label(False)\n",
    "    ax_3d.set_zlabel(ax_labels[var_dim[dim_ind_cart[\"z\"]]], labelpad=-3,)#rotation=\"horizontal\") \n",
    "\n",
    "    ticks = {\n",
    "        \"costheta_mu\": [\"-1\", \"1\"],\n",
    "        \"costheta_K\": [\"-1\", \"1\"],\n",
    "        \"chi\": ['0', r\"$2\\pi$\"],\n",
    "    }      \n",
    "\n",
    "    ax_3d.set_xticks([0, arr.shape[dim_ind_cart[\"x\"]]-1], ticks[var_dim[dim_ind_cart[\"x\"]]])\n",
    "    ax_3d.set_yticks([0, arr.shape[dim_ind_cart[\"y\"]]-1], ticks[var_dim[dim_ind_cart[\"y\"]]])\n",
    "    ax_3d.set_zticks([0, arr.shape[dim_ind_cart[\"z\"]]-1], ticks[var_dim[dim_ind_cart[\"z\"]]])\n",
    "\n",
    "    ax_3d.tick_params(pad=0.3)\n",
    "\n",
    "    ax_3d.set_box_aspect(None, zoom=0.85)\n",
    "\n",
    "    ax_3d.set_title(f\"{note}\", loc=\"center\", y=1)\n",
    "\n",
    "\n",
    "plot_volume_slices(\n",
    "     datasets[\"train\"].features[0], \n",
    "     n_slices=3, \n",
    "     note=r\"$\\delta C_9$ : \"+f\"{datasets[\"train\"].labels[0]}\"\n",
    ")\n",
    "# plt.savefig(f\"{i}\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrain = True\n",
    "\n",
    "nickname = \"cnn_res_with_checkpoints_6k\"\n",
    "\n",
    "model = CNN_Res(nickname, \"../../state/new_physics/models\")\n",
    "\n",
    "if retrain:\n",
    "    learning_rate = 4e-4\n",
    "    epochs = 80\n",
    "    train_batch_size = 32\n",
    "    eval_batch_size = 32\n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_and_eval(\n",
    "        model, \n",
    "        datasets[\"train\"], datasets[\"eval\"], \n",
    "        loss_fn, optimizer, \n",
    "        epochs, \n",
    "        train_batch_size, eval_batch_size, \n",
    "        device, \n",
    "        move_data=False,\n",
    "        scheduler=ReduceLROnPlateau(optimizer, factor=0.9, patience=1),\n",
    "        checkpoint_epochs=5,\n",
    "    )\n",
    "    _, ax = plt.subplots()\n",
    "    plot_epoch_start = 0\n",
    "    plot_loss_curves(\n",
    "        model.loss_table[\"epoch\"][plot_epoch_start:], \n",
    "        model.loss_table[\"train_loss\"][plot_epoch_start:], \n",
    "        model.loss_table[\"eval_loss\"][plot_epoch_start:], \n",
    "        ax\n",
    "    )\n",
    "    ax.set_yscale(\"log\")\n",
    "    plt.show()\n",
    "else:\n",
    "    model.load_final()\n",
    "    # model.load_checkpoint(epoch_number=10)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model (eval dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Res(nickname, \"../../state/new_physics/models\")\n",
    "\n",
    "for ep in range(0, 80, 5):\n",
    "    model.load_checkpoint(epoch_number=ep)\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        yhat = model(datasets[\"eval\"].features)\n",
    "        avgs = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "        stds = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).std(1).detach().cpu().numpy()\n",
    "\n",
    "        y = datasets[\"eval\"].labels\n",
    "        unique_y = y.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "        unique_y\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_prediction_linearity(ax, unique_y, avgs, stds)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    setup_high_quality_mpl_params()\n",
    "\n",
    "\n",
    "print(\"final:\")\n",
    "\n",
    "model.load_final()\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        \n",
    "    yhat = model(datasets[\"eval\"].features)\n",
    "    avgs = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "    stds = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).std(1).detach().cpu().numpy()\n",
    "\n",
    "    y = datasets[\"eval\"].labels\n",
    "    unique_y = y.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "    unique_y\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "plot_prediction_linearity(\n",
    "    ax,\n",
    "    unique_y,\n",
    "    avgs,\n",
    "    stds,\n",
    "    ref_line_buffer=0.05,\n",
    "    xlim=(-2.25, 1.35),\n",
    "    ylim=(-2.25, 1.35),\n",
    "    xlabel=r\"Actual $\\delta C_9$\", \n",
    "    ylabel=r\"Predicted $\\delta C_9$\"\n",
    ")\n",
    "make_plot_note(ax, f\"Image (10 bin), Gen., {common_generate_kwargs[\"num_sets_per_label\"]} boots., {common_generate_kwargs[\"num_events_per_set\"]} events/boots.\", fontsize=\"medium\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model (train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Res(nickname, \"../../state/new_physics/models\")\n",
    "\n",
    "for ep in range(0, 50, 5):\n",
    "    model.load_checkpoint(epoch_number=ep)\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        yhat = model(datasets[\"train\"].features)\n",
    "        avgs = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "        stds = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).std(1).detach().cpu().numpy()\n",
    "\n",
    "        y = datasets[\"train\"].labels\n",
    "        unique_y = y.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "        unique_y\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        plot_prediction_linearity(ax, unique_y, avgs, stds)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "print(\"final:\")\n",
    "\n",
    "setup_high_quality_mpl_params()\n",
    "\n",
    "model = CNN_Res(nickname, \"../../state/new_physics/models\")\n",
    "\n",
    "model.load_final()\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "        \n",
    "    yhat = model(datasets[\"train\"].features)\n",
    "    avgs = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "    stds = yhat.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).std(1).detach().cpu().numpy()\n",
    "\n",
    "    y = datasets[\"train\"].labels\n",
    "    unique_y = y.reshape(-1, common_generate_kwargs[\"num_sets_per_label\"]).mean(1).detach().cpu().numpy()\n",
    "    unique_y\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "plot_prediction_linearity(\n",
    "    ax,\n",
    "    unique_y,\n",
    "    avgs,\n",
    "    stds,\n",
    "    ref_line_buffer=0.05,\n",
    "    xlim=(-2.25, 1.35),\n",
    "    ylim=(-2.25, 1.35),\n",
    "    xlabel=r\"Actual $\\delta C_9$\", \n",
    "    ylabel=r\"Predicted $\\delta C_9$\"\n",
    ")\n",
    "make_plot_note(ax, f\"Image (10 bin), Gen., {common_generate_kwargs[\"num_sets_per_label\"]} boots., {common_generate_kwargs[\"num_events_per_set\"]} events/boots.\", fontsize=\"medium\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maybe_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
